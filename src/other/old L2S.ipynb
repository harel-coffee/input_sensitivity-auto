{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# Neural network high level framework\n",
    "import keras\n",
    "# Sequential is a sequence of blocs\n",
    "# Input deals with the data fed to the network\n",
    "from keras.models import Sequential,Input,Model\n",
    "# Dense is a feedforward layer with fully connected nodes\n",
    "# Dropout allows to keep part of data, and to \"drop out\" a the rest\n",
    "# Flatten makes the data \"flat\", i.e. in one dimension\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "# Conv -> convolution, MaxPooling is relative to Pooling\n",
    "# Activation if the function composing the data in output of a layer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "\n",
    "from learner.mlearner import learn_with_interactions, learn_without_interactions, sample_random, stepwise_feature_selection\n",
    "from learner.model import genModelTermsfromString, Model, genModelfromCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because x264 output is \"m:s\", where m is the number of minutes and s the number of seconds \n",
    "# we define a function to convert this format into the number of seconds\n",
    "def elapsedtime_to_sec(el):\n",
    "    tab = el.split(\":\")\n",
    "    return float(tab[0])*60+float(tab[1])\n",
    "\n",
    "# the data folder, see the markdown there for additional explanations\n",
    "res_dir = \"../../../data/ugc/res_ugc/\"\n",
    "\n",
    "# the list of videos names, e.g. Animation_360P-3e40\n",
    "# we sort the list so we keep the same ids between two launches\n",
    "v_names = sorted(os.listdir(res_dir)) \n",
    "\n",
    "# the list of measurements\n",
    "listVideo = []\n",
    "\n",
    "# we add each dataset in the list, converting the time to the right format\n",
    "# third line asserts that the measures are complete\n",
    "for v in v_names:\n",
    "    data = pd.read_table(res_dir+v, delimiter = ',')\n",
    "    data['etime'] = [*map(elapsedtime_to_sec, data['elapsedtime'])]\n",
    "    assert data.shape == (201,34), v\n",
    "    listVideo.append(data)\n",
    "\n",
    "nbVideos = len(listVideo)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "\n",
    "predDimension=\"size\"\n",
    "\n",
    "# to sample the source and the target using the same seed\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "# a list of features to keep as explicative variables\n",
    "keep_features = ['cabac', '8x8dct', 'mbtree', 'rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', \n",
    "                 'qpmax', 'aq-mode', 'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', \n",
    "                 'b_adapt', 'direct', 'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "# ordinal data to convert into dummies\n",
    "to_dummy_features = ['rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', 'qpmax', 'aq-mode',\n",
    "                    'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', 'b_adapt', 'direct',\n",
    "                     'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "config_tot = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2s implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extraction Process of Performance Models\n",
    "\n",
    "Select a good model for predicting the performance of the source video\n",
    "\n",
    "Original files:\n",
    "- https://github.com/cmu-mars/model-learner/blob/tutorial/learner/mlearner.py for the stepwise selection\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html for the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @PooyanJamshidi:\n",
    "# We just change slightly some functions from the original repository,\n",
    "# mainly because we don't want to add a constant in the model\n",
    "# + steps 2 and 3 were implemented in matlab but we did not find them in python\n",
    "\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \n",
    "    ndim = X.shape[1]\n",
    "    features = [i for i in range(ndim)]\n",
    "    included = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        # forward step (removed a constant)\n",
    "        excluded = list(set(features)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, pd.DataFrame(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.5}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, pd.DataFrame(X[included])).fit()\n",
    "        pvalues = model.pvalues\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.5}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            if verbose:\n",
    "                print(\"Construction of the model completed!\")\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of configuration used for test\n",
    "#pct_test = 0.7\n",
    "\n",
    "# the source video\n",
    "source = listVideo[1]\n",
    "\n",
    "\n",
    "# transform some variables into dummies, to fit the orginal paper\n",
    "# since we don't want to introduce a meaningless constant in the model, \n",
    "# we have to keep all columns\n",
    "\n",
    "#dummies = pd.get_dummies(source[keep_features], \n",
    "#                   drop_first = False,\n",
    "#                   columns=to_dummy_features)\n",
    "\n",
    "# X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "# add interactions\n",
    "# poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "# X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "# performance variable, to predict\n",
    "# y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "# split train test\n",
    "# X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "#                                                                     y_src, \n",
    "#                                                                     test_size=pct_test, \n",
    "#                                                                     random_state=random_state)\n",
    "\n",
    "# the index of the selected features\n",
    "# selected_features = stepwise_selection(X_interact, y_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Active Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A - ] Exploitation : use the source's prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) Sort the coefficients of the previous constructed model\n",
    "\n",
    "##### (ii) Choose the coefficient with the highest value\n",
    "\n",
    "##### (iii) Select the configurations with this feature activated\n",
    "\n",
    "\n",
    "\n",
    "I assumed it was recursive, with a decreasing influence in the selection for a decreasing importance in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ratio_exploitation = 0.3\n",
    "config_tot = 200\n",
    "\n",
    "#reg = LinearRegression()\n",
    "\n",
    "#reg.fit(X_interact[selected_features], y_src)\n",
    "\n",
    "#sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "#nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "\n",
    "#nb_config_selected = 0\n",
    "\n",
    "#assert X_interact.shape[0] >= nb_config_exploitation ; \" Too many configurations to select ! \"\n",
    "\n",
    "def select_exploitation(df, sc, config_selected):\n",
    "    \n",
    "    #number of config left to choose\n",
    "    nb_config = int(nb_config_exploitation - len(config_selected))\n",
    "    \n",
    "    if nb_config == 0:\n",
    "        print(\"Done!\\n\")\n",
    "        return config_selected\n",
    "    \n",
    "    # if we don't have any important coefficient left to help us choose configs\n",
    "    # we take the nb_config first configurations\n",
    "    if len(sc) == 0:\n",
    "        print(\"Selecting \" + str(nb_config) + \" configurations from the rest of the dataset!\")\n",
    "        for conf in df.index[0:nb_config]:\n",
    "            config_selected.append(conf)\n",
    "        return config_selected\n",
    "    \n",
    "    # otherwise we just use the best coef to choose configs\n",
    "    else:\n",
    "        \n",
    "        # we choose the best features coef (biggest absolute value)\n",
    "        most_important_coef = sc[0]\n",
    "        \n",
    "        print(\"Feature : \" + str(most_important_coef))\n",
    "        \n",
    "        # configs with this feature activated\n",
    "        imp_index = np.where(df[most_important_coef]==1)[0]\n",
    "\n",
    "        # number of configs with this feature activated\n",
    "        nb_imp_index = len(imp_index)\n",
    "\n",
    "        # if we have more values to choose \n",
    "        # than the number of configurations with the best feature activated\n",
    "        # we add all the configuration to the selected set\n",
    "        # and we select the rest of the configuration based on other coefficients\n",
    "        if nb_imp_index <= nb_config:\n",
    "            for conf in df.iloc[imp_index].index:\n",
    "                config_selected.append(conf)\n",
    "            if nb_imp_index > 0:\n",
    "                print(\"Added \"+str(nb_imp_index)+ \" values, \"+str(nb_config-nb_imp_index)+\" left to choose \\n\")\n",
    "            # then we apply recursively this method to the rest of the dataframe\n",
    "            return select_exploitation(df.iloc[np.where(df[most_important_coef]==0)[0]], \n",
    "                                          sc[1:len(sc)],\n",
    "                                          config_selected)\n",
    "        \n",
    "        # otherwise we have enough values with this features activated\n",
    "        # to select all the remaining configurations\n",
    "        # so we apply the method to the dataframe containing all the feature activated\n",
    "        # and we select the configuration by using the followings features\n",
    "        else:\n",
    "            return select_exploitation(df.iloc[imp_index], \n",
    "                                 sc[1:len(sc)], \n",
    "                                 config_selected)\n",
    "\n",
    "# exploitation_conf = select_exploitation(X_interact, sorted_coefs, [])\n",
    "\n",
    "# print(\"Selected : \" + str(exploitation_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-] Exploration : Select specific configurations, similar between the source and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I choose to select the group in one step:\n",
    "# if you select config per config, you may choose a local optimal\n",
    "\n",
    "def select_exploration(df, exploitation_conf, id_target, number_group = 100):\n",
    "    \n",
    "    ratio_exploration = 1-ratio_exploitation\n",
    "    nb_exploration = int(config_tot*ratio_exploration)\n",
    "    \n",
    "    target = listVideo[id_target]\n",
    "    \n",
    "    # all the config left for exploration\n",
    "    # total minus those chosen for exploitation\n",
    "    explor_conf = np.setdiff1d(df.index, exploitation_conf)\n",
    "    \n",
    "    # initialization : we take the first nb_exploration config\n",
    "    best_explor = explor_conf[0:nb_exploration]\n",
    "    \n",
    "    # we group it with the exploitation configurations\n",
    "    conf = np.concatenate((exploitation_conf, best_explor), axis=0)\n",
    "    # for the moment, it's our best entropy\n",
    "    best_entropy  = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "    \n",
    "    # then we incrementally select the configurations to diminish the entropy \n",
    "    group_counter = 0\n",
    "    \n",
    "    while group_counter < number_group:\n",
    "        \n",
    "        group_counter +=1\n",
    "        \n",
    "        # current group to 'challenge' the best result\n",
    "        np.random.shuffle(explor_conf)\n",
    "        current_explor = explor_conf[0:nb_exploration]\n",
    "        \n",
    "        # we group it with the exploitation configurations\n",
    "        conf = np.concatenate((exploitation_conf, current_explor), axis=0)\n",
    "        \n",
    "        # we compute the Kullback Leibler divergence between the source and the target\n",
    "        current_entropy = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "        \n",
    "        # we finally take the group giving the lowest entropy\n",
    "        # if this group is better than the best group, we replace it by the new one\n",
    "        if current_entropy > best_entropy:\n",
    "            print(\"Entropy gained : \"+str(current_entropy-best_entropy))\n",
    "            best_entropy = current_entropy\n",
    "            best_explor = current_explor\n",
    "    \n",
    "    return best_explor\n",
    "\n",
    "#print(\"\\nConfigurations kept for exploration : \\n\" + \n",
    "#      str(select_exploration(X_interact, exploitation_conf, 0, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Transfer the knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### I- Stepwise regression #################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                              0 with p-value 3.5793e-55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-58cd780a2b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0ml2s_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-58cd780a2b64>\u001b[0m in \u001b[0;36ml2s_transfer\u001b[0;34m(source_id, target_id, ratio_exploitation, l2s_tr_ratio, pct_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n############### I- Stepwise regression #################\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepwise_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_src_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_src_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n############### II- Sampling #################\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f7742fd3dc6a>\u001b[0m in \u001b[0;36mstepwise_selection\u001b[0;34m(X, y, initial_list, threshold_in, threshold_out, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnew_pval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcluded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_column\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mincluded\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mnew_pval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbest_pval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m                  **kwargs):\n\u001b[1;32m    858\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 859\u001b[0;31m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"weights\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 702\u001b[0;31m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinv_wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wendog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 77\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 672\u001b[0;31m                  **kwargs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m#TODO: remove this when we handle dtype systematically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5347\u001b[0m         \u001b[0;34m\"\"\"internal implementation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5350\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5340\u001b[0m                ['monkey', nan, None]], dtype=object)\n\u001b[1;32m   5341\u001b[0m         \"\"\"\n\u001b[0;32m-> 5342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \"\"\"\n\u001b[1;32m   5202\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5203\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5211\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \"\"\"\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x264/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_consolidated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \"\"\"\n\u001b[1;32m    677\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def l2s_transfer(source_id, target_id, ratio_exploitation = 0.4, l2s_tr_ratio = 0.7, pct_test = 0.5):\n",
    "    \n",
    "    # to sample the source and the target using the same seed\n",
    "    random_state = np.random.randint(0,1000)\n",
    "\n",
    "\n",
    "    # a list of features to keep as explicative variables\n",
    "    keep_features = ['cabac', '8x8dct', 'mbtree', 'rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', \n",
    "                     'qpmax', 'aq-mode', 'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', \n",
    "                     'b_adapt', 'direct', 'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "    # ordinal data to convert into dummies\n",
    "    to_dummy_features = ['rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', 'qpmax', 'aq-mode',\n",
    "                        'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', 'b_adapt', 'direct',\n",
    "                         'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "    # the source video\n",
    "    source = listVideo[source_id]\n",
    "    \n",
    "    # the number of config used in the training\n",
    "    config_tot = int(l2s_tr_ratio*(1-pct_test)*source.shape[1])\n",
    "\n",
    "    # transform some variables into dummies, to fit the orginal paper\n",
    "    # since we don't want to introduce a meaningless constant in the model, \n",
    "    # we have to keep all columns\n",
    "\n",
    "    dummies = pd.get_dummies(source[keep_features], \n",
    "                       drop_first = False,\n",
    "                       columns=to_dummy_features)\n",
    "\n",
    "    X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "    # add interactions\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "    X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "    # performance variable, to predict\n",
    "    y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "    # split train test (-> we only use X_src_train to sample l2s)\n",
    "    X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                        y_src, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "\n",
    "    # we train the model with the training data\n",
    "    print(\"\\n############### I- Stepwise regression #################\\n\")\n",
    "    \n",
    "    selected_features = stepwise_selection(X_src_train, y_src_train)\n",
    "    \n",
    "    print(\"\\n############### II- Sampling #################\\n\")\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "\n",
    "    reg.fit(X_src_train[selected_features], y_src_train)\n",
    "\n",
    "    sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "    nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "    \n",
    "    print(\"A- EXPLOITATION\\n\")\n",
    "    \n",
    "    exploitation_conf = select_exploitation(X_src_train, sorted_coefs, [])\n",
    "    \n",
    "    print(\"\\nB- EXPLORATION\\n\")\n",
    "    \n",
    "    # we ensure we sample the configurations of the training set\n",
    "    # which removes the potential threat of using the configuration of the testing set\n",
    "    # during the training\n",
    "    \n",
    "    exploration_conf = select_exploration(X_src_train, exploitation_conf, target_id, 1000)\n",
    "    \n",
    "    sampled_conf = np.concatenate((exploitation_conf,exploration_conf), axis=0)\n",
    "    \n",
    "    print(sampled_conf)\n",
    "    \n",
    "    print(\"\\n############### III- Transfer #################\\n\")\n",
    "    \n",
    "    # we split the source and the target\n",
    "    \n",
    "    target = listVideo[target_id]\n",
    "    \n",
    "    _, X_src_te, _, y_src_te = train_test_split(X_interact[selected_features], \n",
    "                                                source[predDimension], \n",
    "                                                test_size=pct_test, \n",
    "                                                random_state=random_state)\n",
    "        \n",
    "    _, X_tgt_te, _, y_tgt_te = train_test_split(X_interact[selected_features], \n",
    "                                                target[predDimension], \n",
    "                                                test_size=pct_test, \n",
    "                                                random_state=random_state)\n",
    "    \n",
    "    # instead of using all the configurations, we use the sampled configuration\n",
    "    # ie we remove the unnecessary configurations\n",
    "    \n",
    "    X_src_tr = X_interact[selected_features].iloc[sampled_conf]\n",
    "    y_src_tr = source[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    X_tgt_tr = X_interact[selected_features].iloc[sampled_conf]\n",
    "    y_tgt_tr = target[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    lf = RandomForestRegressor()\n",
    "    lf.fit(X_src_tr, y_src_tr)\n",
    "    y_src_pred_te = np.array(lf.predict(X_src_te)).reshape(-1,1)\n",
    "    \n",
    "    # The shift function, to transfer the prediction from the source to the target\n",
    "    shift = RandomForestRegressor()\n",
    "    shift.fit(np.array(y_src_tr).reshape(-1,1), y_tgt_tr)\n",
    "    y_tgt_pred_te = shift.predict(y_src_pred_te)\n",
    "    \n",
    "    # We return the mean average percentage error \n",
    "    # between the real values of y_test from target \n",
    "    # and the predictions shifted \n",
    "    return mape(y_tgt_te, y_tgt_pred_te)\n",
    "    \n",
    "    \n",
    "l2s_transfer(source_id = 1, target_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
