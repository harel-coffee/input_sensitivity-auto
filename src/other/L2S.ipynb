{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.stats as sc\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from learner.mlearner import learn_with_interactions, learn_without_interactions, sample_random, stepwise_feature_selection\n",
    "from learner.model import genModelTermsfromString, Model, genModelfromCoeff\n",
    "\n",
    "\n",
    "from import_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  configurationID no_8x8dct no_asm no_cabac no_deblock  \\\n",
      "0           0                1      True  False    False       True   \n",
      "1           1             1001     False  False     True       True   \n",
      "2           2             1002      True  False    False      False   \n",
      "3           3             1003     False  False    False       True   \n",
      "4           4             1004     False  False     True      False   \n",
      "\n",
      "  no_fast_pskip no_mbtree no_mixed_refs no_weightb  rc_lookahead  ref  frames  \\\n",
      "0          True     False          True       True          20.0  9.0    1374   \n",
      "1          True      True          True       True          20.0  1.0    1374   \n",
      "2          True     False          True       True          60.0  5.0    1374   \n",
      "3          True      True         False      False          20.0  9.0    1374   \n",
      "4         False      True          True      False          20.0  9.0    1374   \n",
      "\n",
      "     cpu       fps     kbs  etime       size  \n",
      "0  703.2  1315.615  225.03  1.052  1289567.0  \n",
      "1  726.8  1832.999  281.44  0.759  1612870.0  \n",
      "2  614.3  1319.635  239.30  1.049  1371341.0  \n",
      "3  631.4   935.269  249.34  1.474  1428898.0  \n",
      "4  728.1  1315.951  270.22  1.055  1548544.0  \n",
      "There are 25 videos\n"
     ]
    }
   ],
   "source": [
    "listVideo = load_data(drop_default=True)\n",
    "\n",
    "nbVideos = len(listVideo)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "\n",
    "predDimension=\"etime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2s implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Step 1: Extraction Process of Performance Models\n",
    "\n",
    "Select a good model for predicting the performance of the source video\n",
    "\n",
    "Original files:\n",
    "- https://github.com/cmu-mars/model-learner/blob/tutorial/learner/mlearner.py for the stepwise selection\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html for the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @PooyanJamshidi:\n",
    "# We just change slightly some functions from the original repository,\n",
    "# mainly because we don't want to add a constant in the model\n",
    "# + steps 2 and 3 were implemented in matlab but we did not find them in python\n",
    "\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \n",
    "    ndim = X.shape[1]\n",
    "    features = [i for i in range(ndim)]\n",
    "    included = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        # forward step (removed a constant)\n",
    "        excluded = list(set(features)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, pd.DataFrame(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.5}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, pd.DataFrame(X[included])).fit()\n",
    "        pvalues = model.pvalues\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.5}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            if verbose:\n",
    "                print(\"Construction of the model completed!\")\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                              0 with p-value 2.3451e-201\n",
      "Add                             12 with p-value 9.3285e-33\n",
      "Add                              7 with p-value 2.748e-45\n",
      "Add                             82 with p-value 8.7723e-45\n",
      "Add                              6 with p-value 1.2362e-23\n",
      "Add                             13 with p-value 1.352e-23\n",
      "Add                             14 with p-value 7.5903e-206\n",
      "Add                              3 with p-value 1.0257e-18\n",
      "Add                             83 with p-value 1.1616e-23\n",
      "Add                             84 with p-value 6.8461e-97\n",
      "Add                              1 with p-value 1.1333e-23\n",
      "Add                             75 with p-value 1.6628e-23\n",
      "Add                             70 with p-value 7.8824e-22\n",
      "Add                              9 with p-value 4.1825e-21\n",
      "Add                             72 with p-value 3.3327e-29\n",
      "Add                             42 with p-value 8.6591e-22\n",
      "Add                             80 with p-value 1.6946e-09\n",
      "Add                             74 with p-value 3.8599e-05\n",
      "Add                             73 with p-value 1.5644e-33\n",
      "Add                             10 with p-value 1.6204e-10\n",
      "Add                             11 with p-value 3.5779e-243\n",
      "Add                             50 with p-value 0.00021927\n",
      "Add                              4 with p-value 0.0017145\n",
      "Add                             19 with p-value 0.0044947\n",
      "Add                             16 with p-value 0.004307\n",
      "Add                             43 with p-value 0.0059926\n",
      "Add                             56 with p-value 0.008335\n",
      "Construction of the model completed!\n"
     ]
    }
   ],
   "source": [
    "# to sample the source and the target using the same seed\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "# a list of features to keep as explicative variables\n",
    "keep_features = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip', \n",
    "                 'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "# ordinal data to convert into dummies\n",
    "to_dummy_features = ['rc_lookahead','ref']\n",
    "\n",
    "\n",
    "# percentage of configuration used for test\n",
    "pct_test = 0.7\n",
    "\n",
    "# the source video\n",
    "source = listVideo[1]\n",
    "\n",
    "\n",
    "# transform some variables into dummies, to fit the orginal paper\n",
    "# since we don't want to introduce a meaningless constant in the model, \n",
    "# we have to keep all columns\n",
    "\n",
    "dummies = pd.get_dummies(source[keep_features], \n",
    "                   drop_first = False,\n",
    "                   columns=to_dummy_features)\n",
    "\n",
    "X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "# add interactions\n",
    "poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "# performance variable, to predict\n",
    "y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "# split train test\n",
    "X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                    y_src, \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "\n",
    "# the index of the selected features\n",
    "selected_features = stepwise_selection(X_interact, y_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Step 2: Active Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A - ] Exploitation : use the source's prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) Sort the coefficients of the previous constructed model\n",
    "\n",
    "##### (ii) Choose the coefficient with the highest value\n",
    "\n",
    "##### (iii) Select the configurations with this feature activated\n",
    "\n",
    "\n",
    "\n",
    "I assumed it was recursive, with a decreasing influence in the selection for a decreasing importance in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature : 9\n",
      "Feature : 10\n",
      "Feature : 11\n",
      "Feature : 6\n",
      "Feature : 72\n",
      "Feature : 73\n",
      "Feature : 74\n",
      "Feature : 84\n",
      "Added 32 values, 28 left to choose \n",
      "\n",
      "Feature : 83\n",
      "Feature : 82\n",
      "Feature : 7\n",
      "Feature : 12\n",
      "Feature : 13\n",
      "Feature : 14\n",
      "Feature : 0\n",
      "Feature : 3\n",
      "Added 16 values, 12 left to choose \n",
      "\n",
      "Feature : 75\n",
      "Feature : 70\n",
      "Feature : 1\n",
      "Added 8 values, 4 left to choose \n",
      "\n",
      "Feature : 42\n",
      "Feature : 50\n",
      "Feature : 16\n",
      "Feature : 19\n",
      "Feature : 43\n",
      "Feature : 80\n",
      "Feature : 4\n",
      "Added 4 values, 0 left to choose \n",
      "\n",
      "Done!\n",
      "\n",
      "Selected : [4, 28, 54, 104, 109, 135, 146, 213, 235, 284, 368, 386, 408, 437, 461, 463, 502, 585, 697, 743, 751, 772, 784, 797, 820, 842, 863, 869, 925, 1011, 1013, 1021, 131, 150, 369, 390, 452, 579, 680, 755, 773, 800, 836, 861, 862, 1008, 1143, 1146, 209, 243, 282, 406, 434, 464, 515, 865, 113, 770, 813, 867]\n"
     ]
    }
   ],
   "source": [
    "ratio_exploitation = 0.3\n",
    "config_tot = 200\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(X_interact[selected_features], y_src)\n",
    "\n",
    "sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "\n",
    "nb_config_selected = 0\n",
    "\n",
    "assert X_interact.shape[0] >= nb_config_exploitation ; \" Too many configurations to select ! \"\n",
    "\n",
    "def select_exploitation(df, sc, config_selected):\n",
    "    \n",
    "    #number of config left to choose\n",
    "    nb_config = int(nb_config_exploitation - len(config_selected))\n",
    "    \n",
    "    if nb_config == 0:\n",
    "        print(\"Done!\\n\")\n",
    "        return config_selected\n",
    "    \n",
    "    # if we don't have any important coefficient left to help us choose configs\n",
    "    # we take the nb_config first configurations\n",
    "    if len(sc) == 0:\n",
    "        print(\"Selecting \" + str(nb_config) + \" configurations from the rest of the dataset!\")\n",
    "        for conf in df.index[0:nb_config]:\n",
    "            config_selected.append(conf)\n",
    "        return config_selected\n",
    "    \n",
    "    # otherwise we just use the best coef to choose configs\n",
    "    else:\n",
    "        \n",
    "        # we choose the best features coef (biggest absolute value)\n",
    "        most_important_coef = sc[0]\n",
    "        \n",
    "        print(\"Feature : \" + str(most_important_coef))\n",
    "        \n",
    "        # configs with this feature activated\n",
    "        imp_index = np.where(df[most_important_coef]==1)[0]\n",
    "\n",
    "        # number of configs with this feature activated\n",
    "        nb_imp_index = len(imp_index)\n",
    "\n",
    "        # if we have more values to choose \n",
    "        # than the number of configurations with the best feature activated\n",
    "        # we add all the configuration to the selected set\n",
    "        # and we select the rest of the configuration based on other coefficients\n",
    "        if nb_imp_index <= nb_config:\n",
    "            for conf in df.iloc[imp_index].index:\n",
    "                config_selected.append(conf)\n",
    "            if nb_imp_index > 0:\n",
    "                print(\"Added \"+str(nb_imp_index)+ \" values, \"+str(nb_config-nb_imp_index)+\" left to choose \\n\")\n",
    "            # then we apply recursively this method to the rest of the dataframe\n",
    "            return select_config(df.iloc[np.where(df[most_important_coef]==0)[0]], \n",
    "                                          sc[1:len(sc)],\n",
    "                                          config_selected)\n",
    "        \n",
    "        # otherwise we have enough values with this features activated\n",
    "        # to select all the remaining configurations\n",
    "        # so we apply the method to the dataframe containing all the feature activated\n",
    "        # and we select the configuration by using the followings features\n",
    "        else:\n",
    "            return select_config(df.iloc[imp_index], \n",
    "                                 sc[1:len(sc)], \n",
    "                                 config_selected)\n",
    "\n",
    "exploitation_conf = select_exploitation(X_interact, sorted_coefs, [])\n",
    "\n",
    "print(\"Selected : \" + str(exploitation_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-] Exploration : Select specific configurations, similar between the source and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy gained : 0.000606207058237323\n",
      "Entropy gained : 2.6231712971008878e-05\n",
      "Entropy gained : 9.222420139338907e-05\n",
      "Entropy gained : 0.00010228298178902506\n",
      "Entropy gained : 0.0005347582695323372\n",
      "Entropy gained : 0.00010852132709060405\n",
      "\n",
      "Configurations kept for exploration : \n",
      "[  44  969  488  273 1135  337  285  807  566  717  193 1103  582  482\n",
      " 1149  429  132  841  774  397  734  322 1104  277  663 1134  543 1122\n",
      "  475  831 1131  881  251 1145  248  341  625   66 1049  765  907  265\n",
      "  468   29  641  334  478  598  699  720 1151  832  658   51  580  703\n",
      " 1100  333  934  909]\n"
     ]
    }
   ],
   "source": [
    "ratio_exploration = 1-ratio_exploitation\n",
    "nb_exploration = int(config_tot*ratio_exploitation)\n",
    "\n",
    "# I choose to select the group in one step:\n",
    "# if you select config per config, you may choose a local optimal\n",
    "\n",
    "def select_exploration(df, exploitation_conf, id_target, number_group = 100):\n",
    "    \n",
    "    target = listVideo[id_target]\n",
    "    \n",
    "    # all the config left for exploration\n",
    "    # total minus those chosen for exploitation\n",
    "    explor_conf = np.setdiff1d(df.index, exploitation_conf)\n",
    "    \n",
    "    # initialization : we take the first nb_exploration config\n",
    "    best_explor = explor_conf[0:nb_exploration]\n",
    "    \n",
    "    # we group it with the exploitation configurations\n",
    "    conf = np.concatenate((exploitation_conf, best_explor), axis=0)\n",
    "    # for the moment, it's our best entropy\n",
    "    best_entropy  = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "    \n",
    "    # then we incrementally select the configurations to diminish the entropy \n",
    "    group_counter = 0\n",
    "    \n",
    "    while group_counter < number_group:\n",
    "        \n",
    "        group_counter +=1\n",
    "        \n",
    "        # current group to 'challenge' the best result\n",
    "        np.random.shuffle(explor_conf)\n",
    "        current_explor = explor_conf[0:nb_exploration]\n",
    "        \n",
    "        # we group it with the exploitation configurations\n",
    "        conf = np.concatenate((exploitation_conf, current_explor), axis=0)\n",
    "        \n",
    "        # we compute the Kullback Leibler divergence between the source and the target\n",
    "        current_entropy = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "        \n",
    "        # we finally take the group giving the lowest entropy\n",
    "        # if this group is better than the best group, we replace it by the new one\n",
    "        if current_entropy > best_entropy:\n",
    "            print(\"Entropy gained : \"+str(current_entropy-best_entropy))\n",
    "            best_entropy = current_entropy\n",
    "            best_explor = current_explor\n",
    "    \n",
    "    return best_explor\n",
    "\n",
    "print(\"\\nConfigurations kept for exploration : \\n\" + \n",
    "      str(select_exploration(X_interact, exploitation_conf, 0, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Step 3 : Transfer the knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### I- Stepwise regression #################\n",
      "\n",
      "Add                              0 with p-value 1.1648e-206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                             12 with p-value 4.4722e-31\n",
      "Add                              7 with p-value 2.3656e-45\n",
      "Add                             82 with p-value 1.1016e-36\n",
      "Add                             75 with p-value 6.2839e-21\n",
      "Add                             76 with p-value 2.2796e-24\n",
      "Add                              3 with p-value 2.1261e-22\n",
      "Add                              1 with p-value 3.6486e-12\n",
      "Add                             14 with p-value 2.7675e-11\n",
      "Add                             13 with p-value 1.0823e-153\n",
      "Add                             83 with p-value 2.8069e-32\n",
      "Add                             84 with p-value 1.859e-109\n",
      "Add                              9 with p-value 3.2819e-17\n",
      "Add                             42 with p-value 1.9082e-18\n",
      "Add                             72 with p-value 1.2842e-16\n",
      "Add                             77 with p-value 3.3292e-18\n",
      "Add                              6 with p-value 3.7972e-59\n",
      "Drop                             76 with p-value 0.61499\n",
      "Add                             70 with p-value 3.0904e-49\n",
      "Add                             10 with p-value 6.6587e-06\n",
      "Add                             11 with p-value 1.1587e-267\n",
      "Add                             73 with p-value 7.7389e-09\n",
      "Add                             74 with p-value 5.6504e-61\n",
      "Add                             19 with p-value 0.00079726\n",
      "Add                             27 with p-value 0.004307\n",
      "Add                             16 with p-value 0.0041453\n",
      "Add                             50 with p-value 0.0071451\n",
      "Add                             79 with p-value 0.0058305\n",
      "Add                             93 with p-value 0.0082666\n",
      "Construction of the model completed!\n",
      "\n",
      "############### II- Sampling #################\n",
      "\n",
      "A- EXPLOITATION\n",
      "\n",
      "Feature : 7\n",
      "Feature : 82\n",
      "Feature : 83\n",
      "Feature : 84\n",
      "Feature : 74\n",
      "Added 12 values, 48 left to choose \n",
      "\n",
      "Feature : 73\n",
      "Added 10 values, 38 left to choose \n",
      "\n",
      "Feature : 72\n",
      "Added 10 values, 28 left to choose \n",
      "\n",
      "Feature : 6\n",
      "Feature : 14\n",
      "Feature : 13\n",
      "Feature : 12\n",
      "Feature : 9\n",
      "Added 12 values, 16 left to choose \n",
      "\n",
      "Feature : 10\n",
      "Added 11 values, 5 left to choose \n",
      "\n",
      "Feature : 11\n",
      "Feature : 0\n",
      "Feature : 3\n",
      "Added 2 values, 3 left to choose \n",
      "\n",
      "Feature : 75\n",
      "Feature : 70\n",
      "Feature : 1\n",
      "Added 2 values, 1 left to choose \n",
      "\n",
      "Feature : 42\n",
      "Feature : 77\n",
      "Feature : 16\n",
      "Feature : 50\n",
      "Feature : 19\n",
      "Feature : 79\n",
      "Feature : 27\n",
      "Feature : 93\n",
      "Selecting 1 configurations from the rest of the dataset!\n",
      "\n",
      "B- EXPLORATION\n",
      "\n",
      "Entropy gained : 0.0005247018232179372\n",
      "Entropy gained : 0.00033907959248304434\n",
      "Entropy gained : 0.000388942423311521\n",
      "Entropy gained : 0.0007391437243402712\n",
      "Entropy gained : 0.00027611506555010566\n",
      "Entropy gained : 0.00016458036448068966\n",
      "[ 933  576   69 1095  679  580  197 1094 1127  989  693  609  691  803\n",
      "  516  240  748   77   24  692  475  145  790  367  875   76 1005  205\n",
      "  116  577  835  942 1053  311  337  494  945 1111  604  792  333   67\n",
      "  779  928  101  593  286  643  902  559  480  551  177   85  646  278\n",
      "  951  627   43  782  371 1061  170 1008  743  709  339  983  993  914\n",
      " 1034  434  108  461  382  456 1085 1035  226  815  460  184  438 1129\n",
      "  956  500 1138  772  673 1075  763   42  123  287  759  306 1077   92\n",
      "  919  144  255   46  437  160  614 1031  720  375 1000  330  992 1014\n",
      "  518  433  272   70  663  535  554 1118]\n",
      "\n",
      "############### III- Transfer #################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13990661995599477"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def l2s_transfer(i, j, ratio_exploitation = 0.3, l2s_tr_ratio = 0.5, pct_test = 0.7):\n",
    "    \n",
    "    # to sample the source and the target using the same seed\n",
    "    random_state = np.random.randint(0,1000)\n",
    "\n",
    "    # a list of features to keep as explicative variables\n",
    "    keep_features = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip', \n",
    "                     'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "    # ordinal data to convert into dummies\n",
    "    to_dummy_features = ['rc_lookahead','ref']\n",
    "\n",
    "    # the source video\n",
    "    source = listVideo[i]\n",
    "    \n",
    "    # the number of config used in the training\n",
    "    config_tot = int(l2s_tr_ratio*(1-pct_test)*source.shape[1])\n",
    "\n",
    "    # transform some variables into dummies, to fit the orginal paper\n",
    "    # since we don't want to introduce a meaningless constant in the model, \n",
    "    # we have to keep all columns\n",
    "\n",
    "    dummies = pd.get_dummies(source[keep_features], \n",
    "                       drop_first = False,\n",
    "                       columns=to_dummy_features)\n",
    "\n",
    "    X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "    # add interactions\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "    X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "    # performance variable, to predict\n",
    "    y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "    # split train test (-> we only use X_src_train to sample l2s)\n",
    "    X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                        y_src, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "\n",
    "    # we train the model with the training data\n",
    "    print(\"\\n############### I- Stepwise regression #################\\n\")\n",
    "    \n",
    "    selected_features = stepwise_selection(X_src_train, y_src_train)\n",
    "    \n",
    "    print(\"\\n############### II- Sampling #################\\n\")\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "\n",
    "    reg.fit(X_src_train[selected_features], y_src_train)\n",
    "\n",
    "    sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "    nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "    \n",
    "    print(\"A- EXPLOITATION\\n\")\n",
    "    \n",
    "    exploitation_conf = select_exploitation(X_src_train, sorted_coefs, [])\n",
    "    \n",
    "    print(\"\\nB- EXPLORATION\\n\")\n",
    "    \n",
    "    exploration_conf = select_exploration(X_src_train, exploitation_conf, j, 1000)\n",
    "    \n",
    "    sampled_conf=np.concatenate((exploitation_conf,exploration_conf), axis=0)\n",
    "    \n",
    "    print(sampled_conf)\n",
    "    \n",
    "    print(\"\\n############### III- Transfer #################\\n\")\n",
    "    \n",
    "    # we split the source and the target\n",
    "    \n",
    "    target = listVideo[j]\n",
    "    \n",
    "    _, X_src_te, _, y_src_te = train_test_split(source[keep_features], \n",
    "                                                                    source[predDimension], \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "    \n",
    "        \n",
    "    _, X_tgt_te, _, y_tgt_te = train_test_split(target[keep_features], \n",
    "                                                                    target[predDimension],  \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "    X_src_tr = source[keep_features].iloc[sampled_conf]\n",
    "    y_src_tr = source[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    X_tgt_tr = target[keep_features].iloc[sampled_conf]\n",
    "    y_tgt_tr = target[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    lf = LinearRegression()\n",
    "    lf.fit(X_src_tr, y_src_tr)\n",
    "    y_src_pred_te = np.array(lf.predict(X_src_te)).reshape(-1,1)\n",
    "    \n",
    "    # The shift function, to transfer the prediction from the source to the target\n",
    "    shift = LinearRegression()\n",
    "    shift.fit(np.array(y_src_tr).reshape(-1,1), y_tgt_tr)\n",
    "    y_tgt_pred_te = shift.predict(y_src_pred_te)\n",
    "    \n",
    "    # We return the mean average percentage error \n",
    "    # between the real values of y_test from target \n",
    "    # and the predictions shifted \n",
    "    return min(mape(y_tgt_te, y_tgt_pred_te),1)\n",
    "    \n",
    "    \n",
    "l2s_transfer(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
