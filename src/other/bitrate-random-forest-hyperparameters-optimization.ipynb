{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Once and for All - On the Input Sensitivity of Configurable Systems\n",
    "\n",
    "### This notebook contains the comparison of three algorithms; linear regression, random forests and neural networks\n",
    "\n",
    "### RESULT : We choose random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# Neural network high level framework\n",
    "import keras\n",
    "# Sequential is a sequence of blocs\n",
    "# Input deals with the data fed to the network\n",
    "from keras.models import Sequential,Input,Model\n",
    "# Dense is a feedforward layer with fully connected nodes\n",
    "# Dropout allows to keep part of data, and to \"drop out\" a the rest\n",
    "# Flatten makes the data \"flat\", i.e. in one dimension\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "# Conv -> convolution, MaxPooling is relative to Pooling\n",
    "# Activation if the function composing the data in output of a layer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're interested by the bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDimension = \"kbs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#because x264 output is \"m:s\", where m is the number of minutes and s the number of seconds \n",
    "# we define a function to convert this format into the number of seconds\n",
    "def elapsedtime_to_sec(el):\n",
    "    tab = el.split(\":\")\n",
    "    return float(tab[0])*60+float(tab[1])\n",
    "\n",
    "# the data folder, see the markdown there for additional explanations\n",
    "res_dir = \"../../data/ugc/res_ugc/\"\n",
    "\n",
    "# the list of videos names, e.g. Animation_360P-3e40\n",
    "# we sort the list so we keep the same ids between two launches\n",
    "v_names = sorted(os.listdir(res_dir)) \n",
    "\n",
    "# the list of measurements\n",
    "listVideo = []\n",
    "\n",
    "# we add each dataset in the list, converting the time to the right format\n",
    "# third line asserts that the measures are complete\n",
    "for v in v_names:\n",
    "    data = pd.read_table(res_dir+v, delimiter = ',')\n",
    "    data['etime'] = [*map(elapsedtime_to_sec, data['elapsedtime'])]\n",
    "    assert data.shape == (201,34), v\n",
    "    listVideo.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We consider  1397  videos\n"
     ]
    }
   ],
   "source": [
    "print(\" We consider \", len(listVideo), \" videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bitrate rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video0</th>\n",
       "      <th>video1</th>\n",
       "      <th>video2</th>\n",
       "      <th>video3</th>\n",
       "      <th>video4</th>\n",
       "      <th>video5</th>\n",
       "      <th>video6</th>\n",
       "      <th>video7</th>\n",
       "      <th>video8</th>\n",
       "      <th>video9</th>\n",
       "      <th>...</th>\n",
       "      <th>video1387</th>\n",
       "      <th>video1388</th>\n",
       "      <th>video1389</th>\n",
       "      <th>video1390</th>\n",
       "      <th>video1391</th>\n",
       "      <th>video1392</th>\n",
       "      <th>video1393</th>\n",
       "      <th>video1394</th>\n",
       "      <th>video1395</th>\n",
       "      <th>video1396</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>91</td>\n",
       "      <td>104</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>89</td>\n",
       "      <td>26</td>\n",
       "      <td>161</td>\n",
       "      <td>171</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>169</td>\n",
       "      <td>104</td>\n",
       "      <td>164</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>104</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>130</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>160</td>\n",
       "      <td>32</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>166</td>\n",
       "      <td>46</td>\n",
       "      <td>175</td>\n",
       "      <td>171</td>\n",
       "      <td>168</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>193</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>131</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>28</td>\n",
       "      <td>163</td>\n",
       "      <td>161</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>190</td>\n",
       "      <td>193</td>\n",
       "      <td>169</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>169</td>\n",
       "      <td>164</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>168</td>\n",
       "      <td>21</td>\n",
       "      <td>171</td>\n",
       "      <td>160</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>165</td>\n",
       "      <td>176</td>\n",
       "      <td>92</td>\n",
       "      <td>184</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>165</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>163</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>187</td>\n",
       "      <td>112</td>\n",
       "      <td>179</td>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video0  video1  video2  video3  video4  video5  video6  video7  video8  \\\n",
       "index                                                                           \n",
       "0         166      91     104     171     169      89      26     161     171   \n",
       "1         164     104     105     130     168     170      27     160      32   \n",
       "2         169     100     100     131     170     169      28     163     161   \n",
       "3         165     102     102     132     165     168      21     171     160   \n",
       "4         168     108     108      32     123     165      20     130     163   \n",
       "\n",
       "       video9  ...  video1387  video1388  video1389  video1390  video1391  \\\n",
       "index          ...                                                          \n",
       "0         104  ...        104        169        104        164        170   \n",
       "1         171  ...         32        166         46        175        171   \n",
       "2          60  ...        171        170        190        193        169   \n",
       "3          32  ...         36        165        176         92        184   \n",
       "4         130  ...         35        168        187        112        179   \n",
       "\n",
       "       video1392  video1393  video1394  video1395  video1396  \n",
       "index                                                         \n",
       "0            169        104        170        175        169  \n",
       "1            168        171        171        193        168  \n",
       "2            165         60        169        164        123  \n",
       "3            123         32         60         39        159  \n",
       "4            159          4        177         23        170  \n",
       "\n",
       "[5 rows x 1397 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first example ; we compute the rankings of the bitrate distribution for the first input video\n",
    "bitrates = listVideo[0][predDimension]\n",
    "# sorted rankings for the bitrates distribution (0: minimal, 200 : maximal)\n",
    "ind = sorted(range(len(bitrates)), key=lambda k: bitrates[k])\n",
    "# df\n",
    "rankings = pd.DataFrame({\"index\" : range(201), \"video0\" : ind}).set_index(\"index\")\n",
    "\n",
    "for i in np.arange(1,len(listVideo),1):\n",
    "    bitrates = listVideo[i][predDimension]\n",
    "    ind = sorted(range(len(bitrates)), key=lambda k: bitrates[k])\n",
    "    rankings[\"video\"+str(i)] = ind\n",
    "\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading - metrics of the youtube UGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perf_group</th>\n",
       "      <th>SLEEQ_DMOS</th>\n",
       "      <th>BANDING_DMOS</th>\n",
       "      <th>WIDTH</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>SPATIAL_COMPLEXITY</th>\n",
       "      <th>TEMPORAL_COMPLEXITY</th>\n",
       "      <th>CHUNK_COMPLEXITY_VARIATION</th>\n",
       "      <th>COLOR_COMPLEXITY</th>\n",
       "      <th>video_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FILENAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Animation_1080P-01b3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.678859</td>\n",
       "      <td>4.653015</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>-1.475487</td>\n",
       "      <td>-1.547345</td>\n",
       "      <td>-0.892454</td>\n",
       "      <td>-1.210798</td>\n",
       "      <td>-1.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation_1080P-05f8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.741729</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>-0.147257</td>\n",
       "      <td>0.444086</td>\n",
       "      <td>2.545710</td>\n",
       "      <td>2.207516</td>\n",
       "      <td>-1.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation_1080P-0c4f</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.655778</td>\n",
       "      <td>-0.377464</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>0.422320</td>\n",
       "      <td>-0.963192</td>\n",
       "      <td>1.054868</td>\n",
       "      <td>-1.232460</td>\n",
       "      <td>-1.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation_1080P-0cdf</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.294170</td>\n",
       "      <td>-0.059377</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>-0.028644</td>\n",
       "      <td>0.430810</td>\n",
       "      <td>-0.103261</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>-1.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation_1080P-18f5</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.478821</td>\n",
       "      <td>-0.377464</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>1.289017</td>\n",
       "      <td>-0.958767</td>\n",
       "      <td>-0.051295</td>\n",
       "      <td>0.192920</td>\n",
       "      <td>-1.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlog_720P-561e</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.678859</td>\n",
       "      <td>-0.377464</td>\n",
       "      <td>-0.239786</td>\n",
       "      <td>-0.333314</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>-1.414583</td>\n",
       "      <td>-0.652893</td>\n",
       "      <td>0.457201</td>\n",
       "      <td>1.494379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlog_720P-5d08</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.678859</td>\n",
       "      <td>-0.377464</td>\n",
       "      <td>-0.773092</td>\n",
       "      <td>-0.333314</td>\n",
       "      <td>3.257287</td>\n",
       "      <td>-0.303807</td>\n",
       "      <td>-0.437698</td>\n",
       "      <td>-0.158009</td>\n",
       "      <td>1.494379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlog_720P-60f8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444433</td>\n",
       "      <td>0.623920</td>\n",
       "      <td>-0.239786</td>\n",
       "      <td>-0.333314</td>\n",
       "      <td>0.234418</td>\n",
       "      <td>-0.042708</td>\n",
       "      <td>-0.364385</td>\n",
       "      <td>-0.149344</td>\n",
       "      <td>1.494379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlog_720P-6410</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.455739</td>\n",
       "      <td>3.769441</td>\n",
       "      <td>-0.239786</td>\n",
       "      <td>-0.333314</td>\n",
       "      <td>-0.770856</td>\n",
       "      <td>2.121314</td>\n",
       "      <td>1.971065</td>\n",
       "      <td>-0.240326</td>\n",
       "      <td>1.494379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlog_720P-6d56</th>\n",
       "      <td>0</td>\n",
       "      <td>0.629083</td>\n",
       "      <td>-0.353902</td>\n",
       "      <td>-0.239786</td>\n",
       "      <td>-0.333314</td>\n",
       "      <td>-0.329287</td>\n",
       "      <td>0.329026</td>\n",
       "      <td>1.646979</td>\n",
       "      <td>0.565512</td>\n",
       "      <td>1.494379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1397 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      perf_group  SLEEQ_DMOS  BANDING_DMOS     WIDTH  \\\n",
       "FILENAME                                                               \n",
       "Animation_1080P-01b3           1   -0.678859      4.653015  0.383054   \n",
       "Animation_1080P-05f8           2    0.844509      0.741729  0.383054   \n",
       "Animation_1080P-0c4f           1   -0.655778     -0.377464  0.383054   \n",
       "Animation_1080P-0cdf           0   -0.294170     -0.059377  0.383054   \n",
       "Animation_1080P-18f5           0   -0.478821     -0.377464  0.383054   \n",
       "...                          ...         ...           ...       ...   \n",
       "Vlog_720P-561e                 1   -0.678859     -0.377464 -0.239786   \n",
       "Vlog_720P-5d08                 1   -0.678859     -0.377464 -0.773092   \n",
       "Vlog_720P-60f8                 1    0.444433      0.623920 -0.239786   \n",
       "Vlog_720P-6410                 2   -0.455739      3.769441 -0.239786   \n",
       "Vlog_720P-6d56                 0    0.629083     -0.353902 -0.239786   \n",
       "\n",
       "                        HEIGHT  SPATIAL_COMPLEXITY  TEMPORAL_COMPLEXITY  \\\n",
       "FILENAME                                                                  \n",
       "Animation_1080P-01b3  0.332504           -1.475487            -1.547345   \n",
       "Animation_1080P-05f8  0.332504           -0.147257             0.444086   \n",
       "Animation_1080P-0c4f  0.332504            0.422320            -0.963192   \n",
       "Animation_1080P-0cdf  0.332504           -0.028644             0.430810   \n",
       "Animation_1080P-18f5  0.332504            1.289017            -0.958767   \n",
       "...                        ...                 ...                  ...   \n",
       "Vlog_720P-561e       -0.333314            0.978979            -1.414583   \n",
       "Vlog_720P-5d08       -0.333314            3.257287            -0.303807   \n",
       "Vlog_720P-60f8       -0.333314            0.234418            -0.042708   \n",
       "Vlog_720P-6410       -0.333314           -0.770856             2.121314   \n",
       "Vlog_720P-6d56       -0.333314           -0.329287             0.329026   \n",
       "\n",
       "                      CHUNK_COMPLEXITY_VARIATION  COLOR_COMPLEXITY  \\\n",
       "FILENAME                                                             \n",
       "Animation_1080P-01b3                   -0.892454         -1.210798   \n",
       "Animation_1080P-05f8                    2.545710          2.207516   \n",
       "Animation_1080P-0c4f                    1.054868         -1.232460   \n",
       "Animation_1080P-0cdf                   -0.103261         -0.448284   \n",
       "Animation_1080P-18f5                   -0.051295          0.192920   \n",
       "...                                          ...               ...   \n",
       "Vlog_720P-561e                         -0.652893          0.457201   \n",
       "Vlog_720P-5d08                         -0.437698         -0.158009   \n",
       "Vlog_720P-60f8                         -0.364385         -0.149344   \n",
       "Vlog_720P-6410                          1.971065         -0.240326   \n",
       "Vlog_720P-6d56                          1.646979          0.565512   \n",
       "\n",
       "                      video_category  \n",
       "FILENAME                              \n",
       "Animation_1080P-01b3       -1.618194  \n",
       "Animation_1080P-05f8       -1.618194  \n",
       "Animation_1080P-0c4f       -1.618194  \n",
       "Animation_1080P-0cdf       -1.618194  \n",
       "Animation_1080P-18f5       -1.618194  \n",
       "...                              ...  \n",
       "Vlog_720P-561e              1.494379  \n",
       "Vlog_720P-5d08              1.494379  \n",
       "Vlog_720P-60f8              1.494379  \n",
       "Vlog_720P-6410              1.494379  \n",
       "Vlog_720P-6d56              1.494379  \n",
       "\n",
       "[1397 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the file (in itself an aggregation of datasets)\n",
    "# the file is available in the data folder, then ugc_meta\n",
    "# each line is a video, and the columns are the different metrics\n",
    "# provided by Wang et. al.\n",
    "meta = pd.read_csv(\"../../data/ugc/ugc_meta/all_features.csv\").set_index('FILENAME')\n",
    "# category is a high-level characterization of the content of the video\n",
    "# for an example, Sports for a sports video\n",
    "# you can see more details about different categories \n",
    "# and metrics per category in the resources/categories.csv file\n",
    "# I also recommand to read the Youtube UGC paper to understand why we consider these categories\n",
    "meta['category']=[str(meta.index[i]).split('_')[0] for i in range(meta.shape[0])]\n",
    "# a lot of NA, not a big feature importance, seems complicated to compute -> remove NOISE DMOS\n",
    "del meta['NOISE_DMOS']\n",
    "# fill NA with zeros\n",
    "meta = meta.fillna(0)\n",
    "# create a numeric variable (quanti) to compute the category\n",
    "# one video has one and only one category (1 to 1 in sql, so we can join the tables)\n",
    "# again, to do it properly, we should use dummies\n",
    "# but then we cannot compare directly the importances of the metrics to categories \n",
    "cat_tab = pd.Series(meta['category'].values).unique()\n",
    "meta['video_category'] = [np.where(cat_tab==meta['category'][i])[0][0] for i in range(len(meta['category']))]\n",
    "# delete the old columns (quali)\n",
    "del meta['category']\n",
    "# we normalize the variables, since height mean is about 1000, and complexity about 2\n",
    "# different scales do not behave correctly with learning algorithms\n",
    "for col in meta.columns:#[:len(meta.columns)-1]:\n",
    "    inter = np.array(meta[col],float)\n",
    "    meta[col] = (inter-np.mean(inter))/np.std(inter)\n",
    "# left join performance groups to the dataset of metrics\n",
    "# fake groups\n",
    "groups = np.random.randint(0,3, len(listVideo))\n",
    "perf = pd.DataFrame({'FILENAME': np.array([v_names[k][:-4] for k in range(len(v_names))]),\n",
    "              'perf_group' : np.array([k for k in groups])}).set_index('FILENAME')\n",
    "meta_perf = perf.join(meta)\n",
    "# print the results\n",
    "meta_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputec - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listFeatures = [\"cabac\", \"ref\", \"deblock\", \"analyse\", \"me\", \"subme\", \"mixed_ref\", \"me_range\", \"trellis\", \n",
    "                \"8x8dct\", \"fast_pskip\", \"chroma_qp_offset\", \"bframes\", \"b_pyramid\", \n",
    "                \"b_adapt\", \"direct\", \"weightb\", \"open_gop\", \"weightp\", \"scenecut\", \"rc_lookahead\", \n",
    "                \"mbtree\", \"qpmax\", \"aq-mode\"]\n",
    "categorial = ['analyse', 'me', 'direct']\n",
    "val_config = listVideo[0][listFeatures].replace(to_replace =\"None\",value='0')\n",
    "val_config['deblock'] =[int(val[0]) for val in val_config['deblock']]\n",
    "\n",
    "for col in val_config.columns:\n",
    "    if col not in categorial:\n",
    "        arr_col = np.array(val_config[col],int)\n",
    "        arr_col = (arr_col-np.mean(arr_col))/(np.std(arr_col)+1e-5)\n",
    "        val_config[col] = arr_col\n",
    "    else:\n",
    "        if col not in [predDimension,'ranking']:\n",
    "            val_config[col] = [np.where(k==val_config[col].unique())[0][0] for k in val_config[col]]\n",
    "            arr_col = np.array(val_config[col],int)\n",
    "            arr_col = (arr_col-np.mean(arr_col))/(np.std(arr_col)+1e-5)\n",
    "            val_config[col] = arr_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to \"place\" a value (i.e. give a rank to a value) in an ordered list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rank(sorted_perfs, val):\n",
    "    # inputs : a list of sorted performances, a value \n",
    "    # output: the ranking of value in the sorted_perf list \n",
    "    rank = 0\n",
    "    while val > sorted_perfs[rank] and rank < len(sorted_perfs)-1:\n",
    "        rank+=1\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the datasets, train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size :  210447\n"
     ]
    }
   ],
   "source": [
    "# we separate the list of videos into a training (i.e. offline) set and a test set (i.e. online)\n",
    "train_ind, test_ind = train_test_split([k for k in range(len(listVideo))], test_size = 0.25)\n",
    "# training set indexes\n",
    "train_index = [v_names[k][:-4] for k in train_ind]\n",
    "\n",
    "# we add the input properties\n",
    "name_col = list(meta_perf.columns)[1:]\n",
    "\n",
    "# we add the x264 configuration options\n",
    "for vcc in val_config.columns:\n",
    "    name_col.append(vcc)\n",
    "\n",
    "# Then, X (i.e the predicting variables) =  input properties + software configuration options\n",
    "\n",
    "# we add the variable to predict, i.e. y the bitrate performance distribution\n",
    "name_col.append(\"bitrate\")\n",
    "\n",
    "# X length, the number of predicting variables\n",
    "nb_col = len(name_col)\n",
    "# the number of configurations\n",
    "nb_config = 201\n",
    "\n",
    "# generate the datasets = (X,y)\n",
    "def gen_dataset(inputs_names):\n",
    "    # inputs : names of videos\n",
    "    # output : aggregation of multiple (X,y) for all the videos in the list of names provided in input \n",
    "    \n",
    "    # the final dataset\n",
    "    res = pd.DataFrame(np.zeros(nb_config*len(inputs_names)*nb_col).reshape(nb_config*len(inputs_names), nb_col))\n",
    "    res.columns = name_col\n",
    "    \n",
    "    # we add the data video per video\n",
    "    # LINES 6-10 in Algorithm 1\n",
    "    for i in range(len(inputs_names)):\n",
    "        # first, we retrieve the name of the video\n",
    "        video_name = inputs_names[i]\n",
    "        index_video = np.where(np.array([v[:-4] for v in v_names], str)==video_name)[0][0]\n",
    "        # we compute the performance, here\n",
    "        bitrates = listVideo[index_video][predDimension]\n",
    "        # get the input properties of the video\n",
    "        video_prop = np.array(meta_perf.loc[video_name][1:], float)\n",
    "        # compute the avrage value and the standard deviation for the bitrate\n",
    "        # as we said in the paper, it does not change the order of variable\n",
    "        # which is a good property\n",
    "        moy = np.mean(bitrates)\n",
    "        std = np.std(bitrates)\n",
    "        # for each configuration, we add the values of the input properties and the configuration options (=X)\n",
    "        # and the normalized values of bitrates (=y)\n",
    "        for config_id in range(nb_config):\n",
    "            val = list(tuple(video_prop) + tuple(val_config.loc[config_id]))\n",
    "            val.append((bitrates[config_id]-moy)/std)\n",
    "            res.loc[i*nb_config+config_id] = val\n",
    "    return res\n",
    "\n",
    "# training dataset\n",
    "training_data = gen_dataset(train_index)\n",
    "\n",
    "# dimensions of the different sets = a proxy to the measurement cost \n",
    "print(\"Training size : \", training_data.shape[0])\n",
    "\n",
    "# OFFLINE - Training data\n",
    "X_train = np.array(training_data.drop([\"bitrate\"],axis=1), float)\n",
    "y_train = np.array(training_data[\"bitrate\"], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size :  70350\n"
     ]
    }
   ],
   "source": [
    "# test set indexes\n",
    "test_index = [v_names[k][:-4] for k in test_ind]\n",
    "# test dataset\n",
    "test_data = gen_dataset(test_index)\n",
    "\n",
    "X_test = np.array(test_data.drop([\"bitrate\"],axis=1), float)\n",
    "y_test = np.array(test_data[\"bitrate\"], float)\n",
    "\n",
    "print(\"Test size : \", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We used the mean squared error (i.e. we minimize the mse between the predicted and the \"real\" measurements) and chose the parameters giving the minimal value of mse\n",
    "\n",
    "We use a GridSearch algorithm, i.e we test multiple values for each parameter, and selects the best (in terms of mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=5)]: Done 405 out of 405 | elapsed: 33.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'max_depth': [3, 5, None], 'max_features': [5, 15, 33],\n",
       "                         'min_samples_leaf': [2, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_rf = RandomForestRegressor()\n",
    "\n",
    "grid_search_larf = GridSearchCV(estimator = LA_rf,\n",
    "                                param_grid = {'n_estimators': [10, 50, 100],\n",
    "                                              # we didn't include 1 for min_samples_leaf to avoid overfitting\n",
    "                                         'min_samples_leaf' : [2, 5, 10],\n",
    "                                         'max_depth' : [3, 5, None],\n",
    "                                         'max_features' : [5, 15, 33]},\n",
    "                                scoring = 'neg_mean_squared_error',\n",
    "                                verbose = True,\n",
    "                                n_jobs = 5)\n",
    "\n",
    "grid_search_larf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 15,\n",
       " 'min_samples_leaf': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_larf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
