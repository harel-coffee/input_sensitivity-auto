{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Shift (MS) is a transfer learning defined by Valov et al. \n",
    "First, it trains a performance model on the source input and predicts the performance distribution of the source input. \n",
    "Then, it trains a shifting function, predicting the performances of the target input based on the performances of the source. \n",
    "Finally, it applies the shifting function to the predictions of the source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "# Support vector machine - support vector regressor\n",
    "from sklearn.svm import SVR\n",
    "# decision trees\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# gradient boosting trees\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# Neural network high level framework\n",
    "import keras\n",
    "# Sequential is a sequence of blocs\n",
    "# Input deals with the data fed to the network\n",
    "from keras.models import Sequential,Input,Model\n",
    "# Dense is a feedforward layer with fully connected nodes\n",
    "# Dropout allows to keep part of data, and to \"drop out\" a the rest\n",
    "# Flatten makes the data \"flat\", i.e. in one dimension\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "# Conv -> convolution, MaxPooling is relative to Pooling\n",
    "# Activation if the function composing the data in output of a layer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MS:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.pct_test = pct_test\n",
    "        #self.ratio_exploitation = ratio_exploitation\n",
    "        \n",
    "        # the data folder, see the markdown there for additional explanations\n",
    "        res_dir = \"../../../data/ugc/res_ugc/\"\n",
    "        \n",
    "        # the list of videos names, e.g. Animation_360P-3e40\n",
    "        # we sort the list so we keep the same ids between two launches\n",
    "        v_names = sorted(os.listdir(res_dir)) \n",
    "\n",
    "        self.predDimension = \"kbs\"\n",
    "        \n",
    "        # the list of measurements\n",
    "        listVideo = []\n",
    "\n",
    "        # we add each dataset in the list, converting the time to the right format\n",
    "        # third line asserts that the measures are complete\n",
    "        for v in v_names:\n",
    "            data = pd.read_table(res_dir+v, delimiter = ',')\n",
    "            inter = pd.get_dummies(data)\n",
    "            inter[self.predDimension] = data[self.predDimension]\n",
    "            listVideo.append(inter)\n",
    "        \n",
    "        self.listVideo = listVideo\n",
    "        \n",
    "        \n",
    "        # to sample the source and the target using the same seed\n",
    "        self.random_state = np.random.randint(0,1000)\n",
    "        \n",
    "        self.features = ['cabac', '8x8dct', 'mbtree', 'rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', \n",
    "                 'qpmax', 'aq-mode', 'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', \n",
    "                 'b_adapt', 'direct', 'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "    \n",
    "    def mse(self, y_true, y_pred):\n",
    "        return np.mean((y_true-y_pred)**2)\n",
    "    \n",
    "    def learn(self, source_id, target_id, train_size, \n",
    "                    learning_algorithm = RandomForestRegressor, \n",
    "                    shift_function = RandomForestRegressor):\n",
    "    \n",
    "        # the percentage (proportion) of configurations used for the test\n",
    "        # pct_test = 1-nb_config_target_training/len(listVideo[target_id].index)\n",
    "        # print(pct_test)\n",
    "\n",
    "        # random state , i.e. a seed to split the source and the target datasets\n",
    "        # by using the same set of configurations for training and testing\n",
    "        random_state = np.random.randint(0,1000)\n",
    "\n",
    "        # We define the source video, and split it into train-test\n",
    "        source = self.listVideo[source_id]\n",
    "        X_src = source.drop([self.predDimension], axis = 1)\n",
    "        y_src = np.array(source[self.predDimension], dtype=float)\n",
    "        X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_src, \n",
    "                                                                            y_src, \n",
    "                                                                            train_size=train_size,\n",
    "                                                                            random_state=random_state)\n",
    "        #print(X_src_train.shape)\n",
    "        # We define the target video, and split it into train-test\n",
    "        target = self.listVideo[target_id]\n",
    "        X_tgt = target.drop([self.predDimension], axis = 1)\n",
    "        y_tgt = np.array(target[self.predDimension], dtype=float)\n",
    "        X_tgt_train, X_tgt_test, y_tgt_train, y_tgt_test = train_test_split(X_tgt, \n",
    "                                                                            y_tgt, \n",
    "                                                                            train_size=train_size, \n",
    "                                                                            random_state=random_state)\n",
    "\n",
    "        # The learning algorithm, training on the source video\n",
    "        X_src_train2, _, y_src_train2, _ = train_test_split(X_src, y_src, \n",
    "                                                            test_size=0.7)\n",
    "        \n",
    "        lf = learning_algorithm()\n",
    "        lf.fit(X_src_train2, y_src_train2)\n",
    "        y_src_pred_test = np.array(lf.predict(X_src_test)).reshape(-1,1)\n",
    "\n",
    "        # The shift function, to transfer the prediction from the source to the target\n",
    "        shift = shift_function()\n",
    "        shift.fit(np.array(y_src_train).reshape(-1,1), y_tgt_train)\n",
    "        y_tgt_pred_test = shift.predict(y_src.reshape(-1,1))\n",
    "\n",
    "        # We return the mean average percentage error \n",
    "        # between the real values of y_test from target \n",
    "        # and the predictions shifted \n",
    "        return self.mse(y_tgt_pred_test, y_tgt)\n",
    "    \n",
    "    def predict_conf(self, source_id, target_id, train_size, \n",
    "                    learning_algorithm = RandomForestRegressor, \n",
    "                    shift_function = RandomForestRegressor):\n",
    "    \n",
    "        # the percentage (proportion) of configurations used for the test\n",
    "        # pct_test = 1-nb_config_target_training/len(listVideo[target_id].index)\n",
    "        # print(pct_test)\n",
    "\n",
    "        # random state , i.e. a seed to split the source and the target datasets\n",
    "        # by using the same set of configurations for training and testing\n",
    "        random_state = np.random.randint(0,1000)\n",
    "\n",
    "        # We define the source video, and split it into train-test\n",
    "        source = self.listVideo[source_id]\n",
    "        X_src = source.drop([self.predDimension], axis = 1)\n",
    "        y_src = np.array(source[self.predDimension], dtype=float)\n",
    "        X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_src, \n",
    "                                                                            y_src, \n",
    "                                                                            train_size=train_size,\n",
    "                                                                            random_state=random_state)\n",
    "        #print(X_src_train.shape)\n",
    "        # We define the target video, and split it into train-test\n",
    "        target = self.listVideo[target_id]\n",
    "        X_tgt = target.drop([self.predDimension], axis = 1)\n",
    "        y_tgt = np.array(target[self.predDimension], dtype=float)\n",
    "        X_tgt_train, X_tgt_test, y_tgt_train, y_tgt_test = train_test_split(X_tgt, \n",
    "                                                                            y_tgt, \n",
    "                                                                            train_size=train_size, \n",
    "                                                                            random_state=random_state)\n",
    "\n",
    "        # The learning algorithm, training on the source video\n",
    "        X_src_train2, _, y_src_train2, _ = train_test_split(X_src, y_src, \n",
    "                                                            test_size=0.7)\n",
    "        \n",
    "        lf = learning_algorithm()\n",
    "        lf.fit(X_src_train2, y_src_train2)\n",
    "        y_src_pred_test = np.array(lf.predict(X_src_test)).reshape(-1,1)\n",
    "\n",
    "        # The shift function, to transfer the prediction from the source to the target\n",
    "        shift = shift_function()\n",
    "        shift.fit(np.array(y_src_train).reshape(-1,1), y_tgt_train)\n",
    "        y_tgt_pred_test = shift.predict(y_src.reshape(-1,1))\n",
    "\n",
    "        # We return the mean average percentage error \n",
    "        # between the real values of y_test from target \n",
    "        # and the predictions shifted \n",
    "        return np.argmin(y_tgt_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 1752906.0207466183\n",
      "0.9 1180212.96931652\n",
      "0.9 1897579.8515903938\n",
      "0.9 3533435.359147508\n",
      "0.9 1167846.1500647946\n",
      "0.9 980115.2062252816\n"
     ]
    }
   ],
   "source": [
    "ms = MS()\n",
    "\n",
    "for ts in np.arange(5,31,5):\n",
    "    print(pct_test, ms.learn(source_id = 2, target_id = 6, train_size=ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._base.LinearRegression'> 1402725.3941713842\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 1593177.9965469814\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 1771066.38976192\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 1062298.221570041\n",
      "<class 'sklearn.svm._classes.SVR'> 1693598.6880435469\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 477024.9797989845\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 433654.11879539635\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 416416.2724485392\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 532741.3921451636\n",
      "<class 'sklearn.svm._classes.SVR'> 473014.2127069929\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 11725.935165688516\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 5476.942739595304\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 5515.880780477623\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 12031.106470507546\n",
      "<class 'sklearn.svm._classes.SVR'> 4631.240308183757\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 5831065.440052986\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 3748507.6036371174\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 9432613.441799976\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 8158091.661674964\n",
      "<class 'sklearn.svm._classes.SVR'> 8105087.946786626\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 792507.3883593059\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 528300.459563816\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 1049988.836498537\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 758515.6105790148\n",
      "<class 'sklearn.svm._classes.SVR'> 434725.5152842457\n"
     ]
    }
   ],
   "source": [
    "LAs = [LinearRegression, DecisionTreeRegressor, RandomForestRegressor, XGBRegressor, SVR]\n",
    "for i in range(5):\n",
    "    source_id = np.random.randint(0,1000)\n",
    "    target_id = np.random.randint(0,1000)\n",
    "    for la in LAs:\n",
    "        print(la, ms.learn(source_id = source_id, target_id = target_id, \n",
    "                           train_size=20, learning_algorithm=la))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen algorithm :  RandomForestRegressor (however it may depends on the choice of videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._base.LinearRegression'> 456217.51119152317\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 670142.3770900498\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 554727.6716164041\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 628226.4760653581\n",
      "<class 'sklearn.svm._classes.SVR'> 4850385.808003911\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 6398.924680545176\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 11170.511540796018\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 5605.233614417313\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 16088.985135634259\n",
      "<class 'sklearn.svm._classes.SVR'> 8618.201187216728\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 9593810.98738373\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 10670635.162215425\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 4684757.708281321\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 3545923.388881826\n",
      "<class 'sklearn.svm._classes.SVR'> 24912526.982189137\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 10137321.052144868\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 15581358.360958707\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 15112328.67821009\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 11273944.886928478\n",
      "<class 'sklearn.svm._classes.SVR'> 73446955.95778656\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> 370035.1328324472\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> 355625.1197298507\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> 406983.7369410331\n",
      "<class 'xgboost.sklearn.XGBRegressor'> 495998.83183285844\n",
      "<class 'sklearn.svm._classes.SVR'> 2235762.354274517\n"
     ]
    }
   ],
   "source": [
    "LAs = [LinearRegression, DecisionTreeRegressor, RandomForestRegressor, XGBRegressor, SVR]\n",
    "for i in range(5):\n",
    "    source_id = np.random.randint(0,1000)\n",
    "    target_id = np.random.randint(0,1000)\n",
    "    for la in LAs:\n",
    "        print(la, ms.learn(source_id = source_id, target_id = target_id, \n",
    "                           train_size=20, shift_function=la))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen algorithm  for shifting function:  RandomForestRegressor (however it may depends on the choice of videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the configurations for each video of the test set, for 5 configs, 10 configs, ..., 30 configs in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data folder, see the markdown there for additional explanations\n",
    "res_dir = \"../../../data/ugc/res_ugc/\"\n",
    "\n",
    "# the list of videos names, e.g. Animation_360P-3e40\n",
    "# we sort the list so we keep the same ids between two launches\n",
    "v_names = sorted(os.listdir(res_dir)) \n",
    "\n",
    "v_names_train = np.loadtxt(\"../../../results/raw_data/train_names.csv\", dtype= str)\n",
    "v_names_test = np.loadtxt(\"../../../results/raw_data/test_names.csv\", dtype= str)\n",
    "index_train = [i for i in range(len(v_names)) if v_names[i] in v_names_train]\n",
    "index_test = [i for i in range(len(v_names)) if v_names[i] in v_names_test]\n",
    "\n",
    "train_sizes = np.arange(5,31,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MS()\n",
    "ms_confs = dict()\n",
    "for i in range(len(index_test)):\n",
    "    it = index_test[i]\n",
    "    source_index_train = np.random.randint(0, len(v_names_train))\n",
    "    source_id = index_train[source_index_train]\n",
    "    for ts in train_sizes:\n",
    "        ms_confs[(i, ts)] = ms.predict_conf(source_id = source_id, target_id = it, train_size=ts,\n",
    "                                      learning_algorithm = SVR, \n",
    "                                      shift_function = RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_data = pd.DataFrame({\"id_video\" : [i for i in range(len(index_test))]})\n",
    "for ts in train_sizes:\n",
    "    ms_data[\"conf\"+str(ts)] = [ms_confs[(i, ts)] for i in range(len(index_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_data.set_index(\"id_video\").to_csv(\"../../../results/raw_data/MS_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
