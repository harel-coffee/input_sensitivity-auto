{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# Neural network high level framework\n",
    "import keras\n",
    "# Sequential is a sequence of blocs\n",
    "# Input deals with the data fed to the network\n",
    "from keras.models import Sequential,Input,Model\n",
    "# Dense is a feedforward layer with fully connected nodes\n",
    "# Dropout allows to keep part of data, and to \"drop out\" a the rest\n",
    "# Flatten makes the data \"flat\", i.e. in one dimension\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "# Conv -> convolution, MaxPooling is relative to Pooling\n",
    "# Activation if the function composing the data in output of a layer\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "\n",
    "from learner.mlearner import learn_with_interactions, learn_without_interactions, sample_random, stepwise_feature_selection\n",
    "from learner.model import genModelTermsfromString, Model, genModelfromCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because x264 output is \"m:s\", where m is the number of minutes and s the number of seconds \n",
    "# we define a function to convert this format into the number of seconds\n",
    "def elapsedtime_to_sec(el):\n",
    "    tab = el.split(\":\")\n",
    "    return float(tab[0])*60+float(tab[1])\n",
    "\n",
    "# the data folder, see the markdown there for additional explanations\n",
    "res_dir = \"../../../data/ugc/res_ugc/\"\n",
    "\n",
    "# the list of videos names, e.g. Animation_360P-3e40\n",
    "# we sort the list so we keep the same ids between two launches\n",
    "v_names = sorted(os.listdir(res_dir)) \n",
    "\n",
    "# the list of measurements\n",
    "listVideo = []\n",
    "\n",
    "# we add each dataset in the list, converting the time to the right format\n",
    "# third line asserts that the measures are complete\n",
    "for v in v_names:\n",
    "    data = pd.read_table(res_dir+v, delimiter = ',')\n",
    "    data['etime'] = [*map(elapsedtime_to_sec, data['elapsedtime'])]\n",
    "    assert data.shape == (201,34), v\n",
    "    listVideo.append(data)\n",
    "\n",
    "nbVideos = len(listVideo)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "\n",
    "predDimension=\"size\"\n",
    "\n",
    "# to sample the source and the target using the same seed\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "# a list of features to keep as explicative variables\n",
    "keep_features = ['cabac', '8x8dct', 'mbtree', 'rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', \n",
    "                 'qpmax', 'aq-mode', 'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', \n",
    "                 'b_adapt', 'direct', 'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "# ordinal data to convert into dummies\n",
    "to_dummy_features = ['rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', 'qpmax', 'aq-mode',\n",
    "                    'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', 'b_adapt', 'direct',\n",
    "                     'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "config_tot = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2s implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extraction Process of Performance Models\n",
    "\n",
    "Select a good model for predicting the performance of the source video\n",
    "\n",
    "Original files:\n",
    "- https://github.com/cmu-mars/model-learner/blob/tutorial/learner/mlearner.py for the stepwise selection\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html for the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @PooyanJamshidi:\n",
    "# We just change slightly some functions from the original repository,\n",
    "# mainly because we don't want to add a constant in the model\n",
    "# + steps 2 and 3 were implemented in matlab but we did not find them in python\n",
    "\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \n",
    "    ndim = X.shape[1]\n",
    "    features = [i for i in range(ndim)]\n",
    "    included = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        # forward step (removed a constant)\n",
    "        excluded = list(set(features)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, pd.DataFrame(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.5}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, pd.DataFrame(X[included])).fit()\n",
    "        pvalues = model.pvalues\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.5}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            if verbose:\n",
    "                print(\"Construction of the model completed!\")\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of configuration used for test\n",
    "#pct_test = 0.7\n",
    "\n",
    "# the source video\n",
    "#source = listVideo[1]\n",
    "\n",
    "\n",
    "# transform some variables into dummies, to fit the orginal paper\n",
    "# since we don't want to introduce a meaningless constant in the model, \n",
    "# we have to keep all columns\n",
    "\n",
    "#dummies = pd.get_dummies(source[keep_features], \n",
    "#                   drop_first = False,\n",
    "#                   columns=to_dummy_features)\n",
    "\n",
    "# X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "# add interactions\n",
    "# poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "# X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "# performance variable, to predict\n",
    "# y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "# split train test\n",
    "# X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "#                                                                     y_src, \n",
    "#                                                                     test_size=pct_test, \n",
    "#                                                                     random_state=random_state)\n",
    "\n",
    "# the index of the selected features\n",
    "# selected_features = stepwise_selection(X_interact, y_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Active Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A - ] Exploitation : use the source's prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) Sort the coefficients of the previous constructed model\n",
    "\n",
    "##### (ii) Choose the coefficient with the highest value\n",
    "\n",
    "##### (iii) Select the configurations with this feature activated\n",
    "\n",
    "\n",
    "\n",
    "I assumed it was recursive, with a decreasing influence in the selection for a decreasing importance in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ratio_exploitation = 0.3\n",
    "\n",
    "# reg = LinearRegression()\n",
    "\n",
    "# reg.fit(X_interact[selected_features], y_src)\n",
    "\n",
    "# sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "# nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "\n",
    "# nb_config_selected = 0\n",
    "\n",
    "# assert X_interact.shape[0] >= nb_config_exploitation ; \" Too many configurations to select ! \"\n",
    "\n",
    "#number of config left to choose\n",
    "ratio_exploitation = 0.4\n",
    "nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "nb_config = int(nb_config_exploitation - len(config_selected))\n",
    "\n",
    "def select_exploitation(df, sc, config_selected):\n",
    "    \n",
    "    if nb_config == 0:\n",
    "        print(\"Done!\\n\")\n",
    "        return config_selected\n",
    "    \n",
    "    # if we don't have any important coefficient left to help us choose configs\n",
    "    # we take the nb_config first configurations\n",
    "    if len(sc) == 0:\n",
    "        print(\"Selecting \" + str(nb_config) + \" configurations from the rest of the dataset!\")\n",
    "        for conf in df.index[0:nb_config]:\n",
    "            config_selected.append(conf)\n",
    "        return config_selected\n",
    "    \n",
    "    # otherwise we just use the best coef to choose configs\n",
    "    else:\n",
    "        \n",
    "        # we choose the best features coef (biggest absolute value)\n",
    "        most_important_coef = sc[0]\n",
    "        \n",
    "        print(\"Feature : \" + str(most_important_coef))\n",
    "        \n",
    "        # configs with this feature activated\n",
    "        imp_index = np.where(df[most_important_coef]==1)[0]\n",
    "\n",
    "        # number of configs with this feature activated\n",
    "        nb_imp_index = len(imp_index)\n",
    "\n",
    "        # if we have more values to choose \n",
    "        # than the number of configurations with the best feature activated\n",
    "        # we add all the configuration to the selected set\n",
    "        # and we select the rest of the configuration based on other coefficients\n",
    "        if nb_imp_index <= nb_config:\n",
    "            for conf in df.iloc[imp_index].index:\n",
    "                config_selected.append(conf)\n",
    "            if nb_imp_index > 0:\n",
    "                print(\"Added \"+str(nb_imp_index)+ \" values, \"+str(nb_config-nb_imp_index)+\" left to choose \\n\")\n",
    "            # then we apply recursively this method to the rest of the dataframe\n",
    "            return select_exploitation(df.iloc[np.where(df[most_important_coef]==0)[0]], \n",
    "                                          sc[1:len(sc)],\n",
    "                                          config_selected)\n",
    "        \n",
    "        # otherwise we have enough values with this features activated\n",
    "        # to select all the remaining configurations\n",
    "        # so we apply the method to the dataframe containing all the feature activated\n",
    "        # and we select the configuration by using the followings features\n",
    "        else:\n",
    "            return select_exploitation(df.iloc[imp_index], \n",
    "                                 sc[1:len(sc)], \n",
    "                                 config_selected)\n",
    "\n",
    "# exploitation_conf = select_exploitation(X_interact, sorted_coefs, [])\n",
    "\n",
    "# print(\"Selected : \" + str(exploitation_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-] Exploration : Select specific configurations, similar between the source and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I choose to select the group in one step:\n",
    "# if you select config per config, you may choose a local optimal\n",
    "\n",
    "def select_exploration(df, exploitation_conf, id_target, ratio_exploitation, number_group = 100):\n",
    "    \n",
    "    ratio_exploration = 1-ratio_exploitation\n",
    "    nb_exploration = int(config_tot*ratio_exploration)\n",
    "    \n",
    "    target = listVideo[id_target]\n",
    "    \n",
    "    # all the config left for exploration\n",
    "    # total minus those chosen for exploitation\n",
    "    explor_conf = np.setdiff1d(df.index, exploitation_conf)\n",
    "    \n",
    "    # initialization : we take the first nb_exploration config\n",
    "    best_explor = explor_conf[0:nb_exploration]\n",
    "    \n",
    "    # we group it with the exploitation configurations\n",
    "    conf = np.concatenate((exploitation_conf, best_explor), axis=0)\n",
    "    # for the moment, it's our best entropy\n",
    "    best_entropy  = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "    \n",
    "    # then we incrementally select the configurations to diminish the entropy \n",
    "    group_counter = 0\n",
    "    \n",
    "    while group_counter < number_group:\n",
    "        \n",
    "        group_counter +=1\n",
    "        \n",
    "        # current group to 'challenge' the best result\n",
    "        np.random.shuffle(explor_conf)\n",
    "        current_explor = explor_conf[0:nb_exploration]\n",
    "        \n",
    "        # we group it with the exploitation configurations\n",
    "        conf = np.concatenate((exploitation_conf, current_explor), axis=0)\n",
    "        \n",
    "        # we compute the Kullback Leibler divergence between the source and the target\n",
    "        current_entropy = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "        \n",
    "        # we finally take the group giving the lowest entropy\n",
    "        # if this group is better than the best group, we replace it by the new one\n",
    "        if current_entropy > best_entropy:\n",
    "            print(\"Entropy gained : \"+str(current_entropy-best_entropy))\n",
    "            best_entropy = current_entropy\n",
    "            best_explor = current_explor\n",
    "    \n",
    "    return best_explor\n",
    "\n",
    "#print(\"\\nConfigurations kept for exploration : \\n\" + \n",
    "#      str(select_exploration(X_interact, exploitation_conf, 0, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Transfer the knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### I- Stepwise regression #################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                              0 with p-value 6.2451e-53\n",
      "Add                             34 with p-value 6.2451e-53\n",
      "Add                           1137 with p-value 6.1774e-22\n",
      "Add                           2695 with p-value 6.1774e-22\n",
      "Add                            110 with p-value 1.5133e-10\n",
      "Add                           1121 with p-value 2.3129e-07\n",
      "Add                             20 with p-value 3.3417e-09\n",
      "Drop                           2695 with p-value 0.28761\n",
      "Add                           1322 with p-value 3.3417e-09\n",
      "Drop                           1137 with p-value 0.28761\n",
      "Add                           1324 with p-value 3.4686e-13\n",
      "Add                           1950 with p-value 1.3016e-07\n",
      "Add                           1164 with p-value 5.7667e-07\n",
      "Add                            448 with p-value 0.00010647\n",
      "Add                           1255 with p-value 0.00010647\n",
      "Add                           1273 with p-value 0.00010647\n",
      "Add                           1295 with p-value 0.00010647\n",
      "Add                           2470 with p-value 0.00023563\n",
      "Add                           1179 with p-value 0.0010967\n",
      "Add                            112 with p-value 0.00029158\n",
      "Add                             94 with p-value 0.00040297\n",
      "Add                            919 with p-value 0.00036684\n",
      "Add                           1027 with p-value 9.1435e-05\n",
      "Add                            487 with p-value 0.00083528\n",
      "Add                           1404 with p-value 0.00080828\n",
      "Add                           2394 with p-value 0.00036832\n",
      "Add                           2410 with p-value 0.00036832\n",
      "Add                           2633 with p-value 0.00036832\n",
      "Add                           2824 with p-value 0.00036832\n",
      "Add                           2341 with p-value 0.00064835\n",
      "Add                             61 with p-value 0.00061004\n",
      "Add                            135 with p-value 0.00061004\n",
      "Add                            208 with p-value 0.00061004\n",
      "Add                            445 with p-value 0.00061004\n",
      "Add                            490 with p-value 0.00061004\n",
      "Add                            945 with p-value 0.00061004\n",
      "Add                           1088 with p-value 0.00061004\n",
      "Add                           1125 with p-value 0.00061004\n",
      "Add                           1561 with p-value 0.00061004\n",
      "Add                           1890 with p-value 0.00061004\n",
      "Add                           1975 with p-value 0.00061004\n",
      "Add                           2016 with p-value 0.00061004\n",
      "Add                           2095 with p-value 0.00061004\n",
      "Add                           2170 with p-value 0.00061004\n",
      "Add                           2275 with p-value 0.00061004\n",
      "Add                           2308 with p-value 0.00061004\n",
      "Add                           2401 with p-value 0.00061004\n",
      "Add                           2511 with p-value 0.00061004\n",
      "Add                           2560 with p-value 0.00061004\n",
      "Add                           2665 with p-value 0.00061004\n",
      "Add                           2749 with p-value 0.00061004\n",
      "Add                           2750 with p-value 0.00061004\n",
      "Add                           2752 with p-value 0.00061004\n",
      "Add                           2755 with p-value 0.00061004\n",
      "Add                           2758 with p-value 0.00061004\n",
      "Add                           2253 with p-value 0.0010382\n",
      "Add                           2036 with p-value 0.0010131\n",
      "Add                           1143 with p-value 0.00031207\n",
      "Add                           2187 with p-value 0.00016742\n",
      "Add                           1382 with p-value 1.75e-05\n",
      "Add                           2166 with p-value 1.75e-05\n",
      "Add                            155 with p-value 0.00027072\n",
      "Add                           1045 with p-value 0.00025428\n",
      "Add                           1157 with p-value 0.000883\n",
      "Add                           2306 with p-value 0.0005334\n",
      "Add                            293 with p-value 0.0010373\n",
      "Add                           1641 with p-value 0.0019878\n",
      "Add                           1065 with p-value 0.0025068\n",
      "Add                           2644 with p-value 0.0031916\n",
      "Add                           1215 with p-value 0.0047672\n",
      "Add                            165 with p-value 0.0042809\n",
      "Add                           2066 with p-value 0.0019847\n",
      "Add                           2658 with p-value 0.0010601\n",
      "Add                           1144 with p-value 8.7463e-05\n",
      "Add                           1184 with p-value 0.00025434\n",
      "Add                           1690 with p-value 9.5943e-11\n",
      "Drop                           1184 with p-value 0.73245\n",
      "Add                           2160 with p-value 0.00021612\n",
      "Drop                            112 with p-value 0.14385\n",
      "Add                           2175 with p-value 2.7666e-11\n",
      "Add                           2177 with p-value 2.7666e-11\n",
      "Add                           1634 with p-value 0.00091621\n",
      "Add                           2224 with p-value 0.00046177\n",
      "Add                           1408 with p-value 6.7736e-11\n",
      "Add                            735 with p-value 1.637e-13\n",
      "Add                           1417 with p-value 3.0155e-15\n",
      "Drop                           2224 with p-value 0.34556\n",
      "Add                            485 with p-value 0.00051314\n",
      "Add                            122 with p-value 0.00027279\n",
      "Add                           2040 with p-value 0.00010742\n",
      "Add                            406 with p-value 3.3218e-05\n",
      "Add                            408 with p-value 3.3218e-05\n",
      "Add                           1920 with p-value 3.3218e-05\n",
      "Add                           2827 with p-value 4.1808e-05\n",
      "Add                           2230 with p-value 0.00010885\n",
      "Add                            697 with p-value 0.00024487\n",
      "Add                           2237 with p-value 0.00022135\n",
      "Add                           1331 with p-value 2.4825e-27\n",
      "Drop                            485 with p-value 0.71055\n",
      "Add                           2224 with p-value 5.982e-06\n",
      "Add                           2233 with p-value 5.982e-06\n",
      "Add                           2234 with p-value 5.982e-06\n",
      "Add                            718 with p-value 5.8498e-06\n",
      "Add                           2247 with p-value 2.484e-09\n",
      "Add                           2249 with p-value 2.484e-09\n",
      "Add                           2250 with p-value 2.484e-09\n",
      "Add                           1493 with p-value 2.1446e-06\n",
      "Add                           1499 with p-value 2.1446e-06\n",
      "Add                           1502 with p-value 2.1446e-06\n",
      "Add                           1503 with p-value 2.1446e-06\n",
      "Add                           1518 with p-value 2.1446e-06\n",
      "Add                           1519 with p-value 2.1446e-06\n",
      "Add                           1184 with p-value 2.8979e-06\n",
      "Add                           1511 with p-value 2.8979e-06\n",
      "Add                           1330 with p-value 1.9245e-07\n",
      "Add                           2134 with p-value 2.7928e-09\n",
      "Add                           1726 with p-value 4.4537e-05\n",
      "Add                           2407 with p-value 4.4537e-05\n",
      "Add                           2517 with p-value 4.4537e-05\n",
      "Add                           2589 with p-value 4.4537e-05\n",
      "Add                           2819 with p-value 4.4537e-05\n",
      "Add                            485 with p-value 0.00044198\n",
      "Add                           1977 with p-value 0.0045128\n",
      "Add                           2310 with p-value 0.0045128\n",
      "Construction of the model completed!\n",
      "\n",
      "############### II- Sampling #################\n",
      "\n",
      "A- EXPLOITATION\n",
      "\n",
      "Feature : 1295\n",
      "Added 1 values, 79 left to choose \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "select_exploitation() missing 1 required positional argument: 'ratio_exploitation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4cdb7ae1b524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0ml2s_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-4cdb7ae1b524>\u001b[0m in \u001b[0;36ml2s_transfer\u001b[0;34m(source_id, target_id, ratio_exploitation, l2s_tr_ratio, pct_test)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A- EXPLOITATION\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mexploitation_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_exploitation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_src_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_exploitation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nB- EXPLORATION\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-fb3102985c4a>\u001b[0m in \u001b[0;36mselect_exploitation\u001b[0;34m(df, sc, config_selected, ratio_exploitation)\u001b[0m\n\u001b[1;32m     57\u001b[0m             return select_exploitation(df.iloc[np.where(df[most_important_coef]==0)[0]], \n\u001b[1;32m     58\u001b[0m                                           \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                                           config_selected)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# otherwise we have enough values with this features activated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: select_exploitation() missing 1 required positional argument: 'ratio_exploitation'"
     ]
    }
   ],
   "source": [
    "def l2s_transfer(source_id, target_id, ratio_exploitation = 0.4, l2s_tr_ratio = 0.7, pct_test = 0.5):\n",
    "    \n",
    "    # to sample the source and the target using the same seed\n",
    "    random_state = np.random.randint(0,1000)\n",
    "\n",
    "\n",
    "    # a list of features to keep as explicative variables\n",
    "    keep_features = ['cabac', '8x8dct', 'mbtree', 'rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', \n",
    "                     'qpmax', 'aq-mode', 'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', \n",
    "                     'b_adapt', 'direct', 'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "    # ordinal data to convert into dummies\n",
    "    to_dummy_features = ['rc_lookahead', 'analyse', 'me', 'subme', 'mixed_ref', 'me_range', 'qpmax', 'aq-mode',\n",
    "                        'trellis','fast_pskip', 'chroma_qp_offset', 'bframes', 'b_pyramid', 'b_adapt', 'direct',\n",
    "                         'ref', 'deblock', 'weightb', 'open_gop', 'weightp', 'scenecut']\n",
    "\n",
    "    # the source video\n",
    "    source = listVideo[source_id]\n",
    "    \n",
    "    # the number of config used in the training\n",
    "    config_tot = int(l2s_tr_ratio*(1-pct_test)*source.shape[1])\n",
    "\n",
    "    # transform some variables into dummies, to fit the orginal paper\n",
    "    # since we don't want to introduce a meaningless constant in the model, \n",
    "    # we have to keep all columns\n",
    "\n",
    "    dummies = pd.get_dummies(source[keep_features], \n",
    "                       drop_first = False,\n",
    "                       columns=to_dummy_features)\n",
    "\n",
    "    X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "    # add interactions\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "    X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "    # performance variable, to predict\n",
    "    y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "    # split train test (-> we only use X_src_train to sample l2s)\n",
    "    X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                        y_src, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "\n",
    "    # we train the model with the training data\n",
    "    print(\"\\n############### I- Stepwise regression #################\\n\")\n",
    "    \n",
    "    selected_features = stepwise_selection(X_src_train, y_src_train)\n",
    "    \n",
    "    print(\"\\n############### II- Sampling #################\\n\")\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "\n",
    "    reg.fit(X_src_train[selected_features], y_src_train)\n",
    "\n",
    "    sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "    nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "    \n",
    "    print(\"A- EXPLOITATION\\n\")\n",
    "    \n",
    "    exploitation_conf = select_exploitation(X_src_train, sorted_coefs, [])\n",
    "    \n",
    "    print(\"\\nB- EXPLORATION\\n\")\n",
    "    \n",
    "    # we ensure we sample the configurations of the training set\n",
    "    # which removes the potential threat of using the configuration of the testing set\n",
    "    # during the training\n",
    "    \n",
    "    exploration_conf = select_exploration(X_src_train, exploitation_conf, target_id, ratio_exploitation, 1000)\n",
    "    \n",
    "    sampled_conf = np.concatenate((exploitation_conf,exploration_conf), axis=0)\n",
    "    \n",
    "    print(sampled_conf)\n",
    "    \n",
    "    print(\"\\n############### III- Transfer #################\\n\")\n",
    "    \n",
    "    # we split the source and the target\n",
    "    \n",
    "    target = listVideo[target_id]\n",
    "    \n",
    "    _, X_src_te, _, y_src_te = train_test_split(X_interact[selected_features], \n",
    "                                                source[predDimension], \n",
    "                                                test_size=pct_test, \n",
    "                                                random_state=random_state)\n",
    "        \n",
    "    _, X_tgt_te, _, y_tgt_te = train_test_split(X_interact[selected_features], \n",
    "                                                target[predDimension], \n",
    "                                                test_size=pct_test, \n",
    "                                                random_state=random_state)\n",
    "    \n",
    "    # instead of using all the configurations, we use the sampled configuration\n",
    "    # ie we remove the unnecessary configurations\n",
    "    \n",
    "    X_src_tr = X_interact[selected_features].iloc[sampled_conf]\n",
    "    y_src_tr = source[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    X_tgt_tr = X_interact[selected_features].iloc[sampled_conf]\n",
    "    y_tgt_tr = target[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    lf = RandomForestRegressor()\n",
    "    lf.fit(X_src_tr, y_src_tr)\n",
    "    y_src_pred_te = np.array(lf.predict(X_src_te)).reshape(-1,1)\n",
    "    \n",
    "    # The shift function, to transfer the prediction from the source to the target\n",
    "    shift = RandomForestRegressor()\n",
    "    shift.fit(np.array(y_src_tr).reshape(-1,1), y_tgt_tr)\n",
    "    y_tgt_pred_te = shift.predict(y_src_pred_te)\n",
    "    \n",
    "    # We return the mean average percentage error \n",
    "    # between the real values of y_test from target \n",
    "    # and the predictions shifted \n",
    "    return mape(y_tgt_te, y_tgt_pred_te)\n",
    "    \n",
    "    \n",
    "l2s_transfer(source_id = 1, target_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
