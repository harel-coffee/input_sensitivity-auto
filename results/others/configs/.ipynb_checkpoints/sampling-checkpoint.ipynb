{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the uniformity of sampled configurations\n",
    "\n",
    "To select the configuration options, we read the documentation of each system. \n",
    "\n",
    "We manually extract the options affecting the performances of the system according to the documentation. \n",
    "\n",
    "We then sample \\#C configurations by using a random sampling. \n",
    "\n",
    "We check the uniformity of the different option values with a Kolmogorov-Smirnov test applied to each configuration option. \n",
    "\n",
    "This notebook details the different results related to these tests, for each system and each set of configurations kept for this system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Kolmogorov-Smirnov test\n",
    "\n",
    "We used one-sample Kolmogorov-Smirnov tests to compare the cumulative distributive function (aka cdf) of the generated distribution of values for configuration options to the theorical uniform distribution.\n",
    "\n",
    "The idea of this test is to study the maximal difference of two cdfs, (i.e. $max_{x}|F_{1}(x) - F_{2}(x)|$, where $F_{1}$ and $F_{2}$ are the two cdfs). The bigger the difference, the more the distributions are far from each other.\n",
    "\n",
    "The one-sample version of this test compares the empirical cdf ($F_{1} =  F_{emp}$) to the theorical cdf ($F_{2} =  F_{t}$). Here, we want the theorical law to be uniform. Let us say that an option has ten ordered values $ k = 1 ... 10$. Then, the empirical cdf respects $\\forall k \\in [|1,10|], F_{emp}(k) =  c(k)*\\frac{1}{\\#(config)}$, where c(k) is the count of ``k`` value occurences, while the theorical cdf respects $\\forall k \\in [|1,10|], F_{t}(k) = P(X<=k) = \\frac{k}{10}$.\n",
    "\n",
    "We choose the threshold $0.05$. The null hypothesis of same distribution (i.e. the sampling can be considered as uniform) is rejected if $pval < 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "# get interactions of features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# no warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/\"\n",
    "name_systems = [\"nodejs\", \"poppler\", \"xz\", \"x264\", \"gcc\", \"lingeling\", \"sqlite\", \"imagemagick\"]\n",
    "\n",
    "data = dict()\n",
    "inputs_name = dict()\n",
    "inputs_count = dict()\n",
    "\n",
    "inputs_perf = dict()\n",
    "\n",
    "inputs_perf[\"gcc\"] = [\"size\", \"ctime\", \"exec\"]\n",
    "inputs_perf[\"lingeling\"] = [\"conflicts\", \"cps\", \"reductions\"]\n",
    "inputs_perf[\"nodejs\"] = [\"ops\"]\n",
    "inputs_perf[\"poppler\"] = [\"size\", \"time\"]\n",
    "inputs_perf[\"sqlite\"] = [\"q\"+str(i+1) for i in range(15)]\n",
    "inputs_perf[\"x264\"] = [\"size\", \"kbs\", \"fps\", \"etime\", \"cpu\"]\n",
    "inputs_perf[\"xz\"] = [\"size\", \"time\"]\n",
    "\n",
    "\n",
    "inputs_feat = dict()\n",
    "\n",
    "inputs_feat[\"gcc\"] = [\"optim\",\"-floop-interchange\",\"-fprefetch-loop-arrays\",\"-ffloat-store\",\"-fno-asm\"]\n",
    "inputs_feat[\"imagemagick\"] = [\"-limit memory\",\"-posterize\",\"-gaussian-blur\",\"-limit thread\",\"-quality\"]\n",
    "inputs_feat[\"lingeling\"] = [\"--boost\", \"--carduse\", \"--decompose\", \"--gluescale\", \"--lkhd\", \"--memlim\", \n",
    "\"--minimize\", \"--prbsimple\", \"--sweepirr\", \"--sweepred\"]\n",
    "inputs_feat[\"nodejs\"] = [\"--jitless\", \"--experimental-wasm-modules\", \"--experimental-vm-modules\",\n",
    "                         \"--preserve-symlinks-main\",\"--no-warnings\",\"--node-memory-debug\"]\n",
    "inputs_feat[\"poppler\"] = [\"format\",\"j\",\"jp2\",\"jbig2\",\"ccitt\"]\n",
    "inputs_feat[\"sqlite\"] = [\"-deserialize\", \"-memtrace\", \"-maxsize\", \"-append\", \"-output\"]\n",
    "inputs_feat[\"x264\"] = [\"cabac\", \"ref\", \"deblock\", \"analyse\", \"me\", \"subme\", \"mixed_ref\", \"me_range\", \"trellis\", \n",
    "                \"8x8dct\", \"fast_pskip\", \"chroma_qp_offset\", \"bframes\", \"b_pyramid\", \"b_adapt\", \"direct\", \n",
    "                \"weightb\", \"open_gop\", \"weightp\", \"scenecut\", \"rc_lookahead\", \"mbtree\", \"qpmax\", \"aq-mode\"]\n",
    "inputs_feat[\"xz\"] = [\"memory\",\"format\",\"level\",\"depth\"]\n",
    "\n",
    "\n",
    "inputs_categ = dict()\n",
    "\n",
    "inputs_categ[\"gcc\"] = [\"optim\"]\n",
    "inputs_categ[\"lingeling\"] = []\n",
    "inputs_categ[\"nodejs\"] = []\n",
    "inputs_categ[\"poppler\"] = [\"format\"]\n",
    "inputs_categ[\"sqlite\"] = []\n",
    "inputs_categ[\"x264\"] = ['analyse', 'me', 'direct', 'deblock']\n",
    "inputs_categ[\"xz\"] = ['memory', 'format']\n",
    "\n",
    "\n",
    "for ns in name_systems:\n",
    "    \n",
    "    data_path = data_dir+ns+'/'\n",
    "    \n",
    "    inputs = sorted(os.listdir(data_path))\n",
    "    inputs.remove('others')\n",
    "\n",
    "    inputs_name[ns] = inputs\n",
    "    inputs_count[ns] = len(inputs)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        loc = data_path+inputs[i]\n",
    "        data[ns, i] = pd.read_csv(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First a function  to replace the categorical values with numericals one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       dia\n",
      "1       hex\n",
      "2       hex\n",
      "3       umh\n",
      "4       hex\n",
      "       ... \n",
      "196     hex\n",
      "197     hex\n",
      "198     hex\n",
      "199     hex\n",
      "200    tesa\n",
      "Name: me, Length: 201, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 3., 2., 1., 4., 3., 2., 2., 2., 1., 2., 2., 3., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 2., 4., 4., 2., 1., 2., 2., 2., 3., 2., 2.,\n",
       "       2., 2., 2., 2., 1., 3., 2., 2., 2., 2., 2., 3., 3., 3., 3., 1., 3.,\n",
       "       3., 3., 3., 2., 2., 1., 3., 3., 3., 2., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 2., 1., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 1., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 2., 4., 4., 1., 1., 4., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 2., 2., 3., 4., 1., 1., 2., 1., 1., 1., 4., 1., 1., 1.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 4., 2., 1., 1.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       3., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_with_numerical_values(arr):\n",
    "    \n",
    "    ### Input :\n",
    "    #### arr an array of string, whatever the strings\n",
    "    \n",
    "    ### Output :\n",
    "    #### num_arr, with numerical values corresponding to the string values\n",
    "    \n",
    "    #### eg if arr is ['a', 'c', 'b', 'a', 'b'], arr_num is [1, 2, 3, 1, 3]\n",
    "    \n",
    "    #### we first isolate the values present in the array arr\n",
    "    #### in our little example, values would be equal to ['a', 'b', 'c'] \n",
    "    values = pd.Series(ma).unique()\n",
    "    \n",
    "    #### a list of list, for each value, the list of indexes for this value\n",
    "    index_values = [np.where(ma==val)[0] for val in values]\n",
    "\n",
    "    #### init the resulting array\n",
    "    num_arr = np.zeros(len(ma))\n",
    "\n",
    "    #### replace with the actual indexes\n",
    "    for i in range(len(index_values)):\n",
    "        for ind_val in index_values[i]:\n",
    "            num_arr[ind_val] = i+1\n",
    "    \n",
    "    #### returning the array with numerical values\n",
    "    return num_arr\n",
    "\n",
    "### Testing with an example \n",
    "ma = data[\"x264\", 1][inputs_categ[\"x264\"][1]]\n",
    "print(ma)\n",
    "replace_with_numerical_values(ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, a function to check the uniformity for a software system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uniformity(ns):\n",
    "    \n",
    "    ### Input:\n",
    "    #### ns, the name of the software system\n",
    "    \n",
    "    ### Output:\n",
    "    #### Print the list of options, and says if it is uniform or not based on the configuration space\n",
    "    \n",
    "    # first, we define the dataframe we are working with\n",
    "    # the first dataframe with configurations, they are all the same anyway in terms of configurations\n",
    "    df = data[ns, 0]\n",
    "    \n",
    "    # we store the number of lines in the dataframe, nbconfig\n",
    "    nb_config = df.shape[0]\n",
    "    \n",
    "    # First, we replace the values of options that are neither boolean nor numericals\n",
    "    option_names = inputs_feat[ns]\n",
    "    \n",
    "    for opt_name in option_names:\n",
    "        # we use the previous function on the distribution of performance\n",
    "        # perf = replace_with_numerical_values(df[opt_name])\n",
    "        perf = np.copy(df[opt_name])\n",
    "        # we count the number per value\n",
    "        opt_values_count = pd.Series(perf).value_counts()\n",
    "        # we normalize\n",
    "        opt_values_count /= nb_config\n",
    "        # we initiate the cumulative distributive function array, to store its values\n",
    "        cdf_values = []\n",
    "        # the sum of previous values\n",
    "        s = 0\n",
    "        # we add each value separately, to the total sum and to the array\n",
    "        for opt_val_count in opt_values_count:\n",
    "            s+=opt_val_count\n",
    "            cdf_values.append(s)\n",
    "        # finally we add 1 to the values, it is the end of the array\n",
    "        cdf_values.append(1)\n",
    "        # we apply the Kolmogorov-Smirnov test\n",
    "        pval = stats.kstest(cdf_values, 'uniform').pvalue\n",
    "        # we display the results\n",
    "        print(opt_name, \", p-val = \", str(round(pval,3))+\",\", (pval>=0.05)*\"Uniform sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for each software system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim , p-val =  0.423, Uniform sampling\n",
      "-floop-interchange , p-val =  0.074, Uniform sampling\n",
      "-fprefetch-loop-arrays , p-val =  0.074, Uniform sampling\n",
      "-ffloat-store , p-val =  0.074, Uniform sampling\n",
      "-fno-asm , p-val =  0.074, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"gcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for gcc!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imagemagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-limit memory , p-val =  0.423, Uniform sampling\n",
      "-posterize , p-val =  0.309, Uniform sampling\n",
      "-gaussian-blur , p-val =  0.188, Uniform sampling\n",
      "-limit thread , p-val =  0.259, Uniform sampling\n",
      "-quality , p-val =  0.188, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"imagemagick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for imagemagick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lingeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--boost , p-val =  0.074, Uniform sampling\n",
      "--carduse , p-val =  0.188, Uniform sampling\n",
      "--decompose , p-val =  0.074, Uniform sampling\n",
      "--gluescale , p-val =  0.423, Uniform sampling\n",
      "--lkhd , p-val =  0.2, Uniform sampling\n",
      "--memlim , p-val =  0.074, Uniform sampling\n",
      "--minimize , p-val =  0.074, Uniform sampling\n",
      "--prbsimple , p-val =  0.188, Uniform sampling\n",
      "--sweepirr , p-val =  0.188, Uniform sampling\n",
      "--sweepred , p-val =  0.157, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"lingeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for lingeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodeJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--jitless , p-val =  0.074, Uniform sampling\n",
      "--experimental-wasm-modules , p-val =  0.074, Uniform sampling\n",
      "--experimental-vm-modules , p-val =  0.074, Uniform sampling\n",
      "--preserve-symlinks-main , p-val =  0.074, Uniform sampling\n",
      "--no-warnings , p-val =  0.074, Uniform sampling\n",
      "--node-memory-debug , p-val =  0.074, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"nodejs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for nodejs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format , p-val =  0.074, Uniform sampling\n",
      "j , p-val =  0.074, Uniform sampling\n",
      "jp2 , p-val =  0.074, Uniform sampling\n",
      "jbig2 , p-val =  0.074, Uniform sampling\n",
      "ccitt , p-val =  0.074, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"poppler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for poppler!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-deserialize , p-val =  0.074, Uniform sampling\n",
      "-memtrace , p-val =  0.074, Uniform sampling\n",
      "-maxsize , p-val =  0.0, \n",
      "-append , p-val =  0.074, Uniform sampling\n",
      "-output , p-val =  0.0, \n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sqlite\", 1][\"-maxsize\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sqlite\", 1][\"-output\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for SQLite, there are problems with memtrace and output -> they always have tha same value at 0.\n",
    "It explains why they are not changing, to take into account when reading RQ2 and RQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabac , p-val =  0.065, Uniform sampling\n",
      "ref , p-val =  0.084, Uniform sampling\n",
      "deblock , p-val =  0.051, Uniform sampling\n",
      "analyse , p-val =  0.061, Uniform sampling\n",
      "me , p-val =  0.081, Uniform sampling\n",
      "subme , p-val =  0.556, Uniform sampling\n",
      "mixed_ref , p-val =  0.074, Uniform sampling\n",
      "me_range , p-val =  0.026, \n",
      "trellis , p-val =  0.155, Uniform sampling\n",
      "8x8dct , p-val =  0.018, \n",
      "fast_pskip , p-val =  0.018, \n",
      "chroma_qp_offset , p-val =  0.074, Uniform sampling\n",
      "bframes , p-val =  0.044, \n",
      "b_pyramid , p-val =  0.005, \n",
      "b_adapt , p-val =  0.083, Uniform sampling\n",
      "direct , p-val =  0.099, Uniform sampling\n",
      "weightb , p-val =  0.015, \n",
      "open_gop , p-val =  0.014, \n",
      "weightp , p-val =  0.11, Uniform sampling\n",
      "scenecut , p-val =  0.008, \n",
      "rc_lookahead , p-val =  0.179, Uniform sampling\n",
      "mbtree , p-val =  0.074, Uniform sampling\n",
      "qpmax , p-val =  0.0, \n",
      "aq-mode , p-val =  0.062, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"x264\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for x264 there are some options me_range, 8x8dct, bframes, b_pyramid, weightb, open_gop, and qpmax, that did not pass the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    154\n",
      "24     47\n",
      "Name: me_range, dtype: int64\n",
      "1    159\n",
      "0     42\n",
      "Name: 8x8dct, dtype: int64\n",
      "3     115\n",
      "0      37\n",
      "16     25\n",
      "8      24\n",
      "Name: bframes, dtype: int64\n",
      "2       155\n",
      "None     38\n",
      "1         8\n",
      "Name: b_pyramid, dtype: int64\n",
      "1       162\n",
      "None     39\n",
      "Name: weightb, dtype: int64\n",
      "0       163\n",
      "None     38\n",
      "Name: open_gop, dtype: int64\n",
      "69    201\n",
      "Name: qpmax, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = data[\"x264\",1]\n",
    "\n",
    "val = [\"me_range\", \"8x8dct\", \"bframes\", \"b_pyramid\", \"weightb\", \"open_gop\", \"qpmax\"]\n",
    "\n",
    "for v in val:\n",
    "    print(df[v].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For me_range, too many \"24\" values\n",
    "\n",
    "- For 8x8dct, too many \"1\" values\n",
    "\n",
    "- For bframes, too many \"3\" values\n",
    "\n",
    "- For b_pyramid, too many \"2\" values\n",
    "\n",
    "- For weightb, too many \"0\" values\n",
    "\n",
    "- For qpmax, one value for all the array\n",
    "\n",
    "It is OK since these values are not influential, but we will be careful when commenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory , p-val =  0.188, Uniform sampling\n",
      "format , p-val =  0.074, Uniform sampling\n",
      "level , p-val =  0.162, Uniform sampling\n",
      "depth , p-val =  0.188, Uniform sampling\n"
     ]
    }
   ],
   "source": [
    "check_uniformity(\"xz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for xz, OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
