{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third research question results\n",
    "\n",
    "RQ1 and RQ2 study how inputs affect (1) performance distributions and (2) the effects of different configuration options. \n",
    "However, the performance distributions could change in a negligible way, without affecting the software user's experience. \n",
    "Before concluding on the real impact of the input sensitivity, it is necessary to quantify how much this performance changes from one input to another. \n",
    "Next, we ask whether adapting the software to its input data is worth the cost of finding the right set of parameters \\ie the concrete impact of input sensitivity. \n",
    "\n",
    "\n",
    "## RQ3 - Can we ignore input sensitivity?\n",
    "\n",
    "\n",
    "To estimate how much we can lose, we first define two scenarios S1 and S2:\n",
    "\n",
    "- *S1 - Baseline.* In this scenario, we just train a simple performance model on an input - i.e. the *target* input. We choose the best configuration according to the model, configure the related software with it and execute it with the target input.\n",
    "- *S2 - Ignoring input sensitivity.* In this scenario, we train a model on a given input i.e. the *source* input, and then predict the best configuration for this source input. If we ignore the threat of input sensitivity, we can easily reuse this model for any other input, including the target input defined in S1. Finally, we execute the software with the configuration predicted by our model on the *target* input.\n",
    "\n",
    "In this part, we systematically compare S1 and S2 in terms of performance for all inputs, all performance properties and all software systems. \n",
    "For S1, we repeat the scenario five times with different sources, uniformly chosen among other inputs and consider the average performance.\n",
    "For both scenarios, and due to the imprecision of the learning procedure, the models can recommend sub-optimal configurations. \n",
    "To avoid adding this imprecision to the effect of input sensitivity, and in order to be fair, we consider that the models are oracles i.e. that they predict the best configuration each time.\n",
    "\n",
    "\n",
    "**Performance ratio.**\n",
    "To compare S1 and S2, we use a performance ratio i.e. the performance obtained in S1 over the performance obtained in S2. \n",
    "If the ratio is equal to 1, there is no difference between S1 and S2 and the input sensitivity does not exist.\n",
    "A ratio of 1.4 would suggest that the performance of S1 is worth 1.4 times the performance of S2; therefore, it is possible to gain up to $(1.4-1)*100=40\\%$ performance by choosing S1 instead of S2. \n",
    "We also report on the standard deviation of the performance ratio distribution. \n",
    "A standard deviation of 0 implies that for each input, we gain or lose the same proportion of performance when picking S1 over S2. \n",
    "As a comparison, we compute the performance ratio between extreme configurations i.e. the best over the worst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for arrays\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "# high-level plots\n",
    "import seaborn as sns\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# machine learning library\n",
    "# Principal Component Analysis - determine new axis for representing data\n",
    "from sklearn.decomposition import PCA\n",
    "# Random Forests -> vote between decision trees\n",
    "# Gradient boosting -> instead of a vote, upgrade the same tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "# To add interactions in linear regressions models\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Elasticnet is an hybrid method between ridge and Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "# To separate the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Simple clustering (iterative steps)\n",
    "from sklearn.cluster import KMeans\n",
    "# get interactions of features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# we use it to interact with the file system\n",
    "import os\n",
    "# compute time\n",
    "from time import time\n",
    "\n",
    "# statistics\n",
    "import scipy.stats as sc\n",
    "# hierarchical clustering, clusters\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, leaves_list\n",
    "from scipy import stats\n",
    "# statistical tests\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# no warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/\"\n",
    "name_systems = [\"nodejs\", \"poppler\", \"xz\", \"x264\", \"gcc\", \"lingeling\", \"sqlite\"]\n",
    "\n",
    "data = dict()\n",
    "inputs_name = dict()\n",
    "inputs_count = dict()\n",
    "\n",
    "inputs_perf = dict()\n",
    "\n",
    "inputs_perf[\"gcc\"] = [\"size\", \"ctime\", \"exec\"]\n",
    "inputs_perf[\"lingeling\"] = [\"conflicts\", \"cps\", \"reductions\"]\n",
    "inputs_perf[\"nodejs\"] = [\"ops\"]\n",
    "inputs_perf[\"poppler\"] = [\"size\", \"time\"]\n",
    "#inputs_perf[\"sqlite\"] = [\"q\"+str(i+1) for i in range(15)]\n",
    "#not enough room\n",
    "inputs_perf[\"sqlite\"] = [\"q1\",\"q12\",\"q14\"]\n",
    "inputs_perf[\"x264\"] = [\"size\", \"kbs\", \"fps\", \"etime\", \"cpu\"]\n",
    "inputs_perf[\"xz\"] = [\"size\", \"time\"]\n",
    "\n",
    "\n",
    "inputs_feat = dict()\n",
    "\n",
    "inputs_feat[\"gcc\"] = [\"optim\",\"-floop-interchange\",\"-fprefetch-loop-arrays\",\"-ffloat-store\",\"-fno-asm\"]\n",
    "inputs_feat[\"lingeling\"] = [\"--boost\", \"--carduse\", \"--decompose\", \"--gluescale\", \"--lkhd\", \"--memlim\", \n",
    "\"--minimize\", \"--prbsimple\", \"--sweepirr\", \"--sweepred\"]\n",
    "inputs_feat[\"nodejs\"] = [\"--jitless\", \"--experimental-wasm-modules\", \"--experimental-vm-modules\",\n",
    "                         \"--preserve-symlinks-main\",\"--no-warnings\",\"--node-memory-debug\"]\n",
    "inputs_feat[\"poppler\"] = [\"format\",\"j\",\"jp2\",\"jbig2\",\"ccitt\"]\n",
    "inputs_feat[\"sqlite\"] = [\"-deserialize\", \"-memtrace\", \"-maxsize\", \"-append\", \"-output\"]\n",
    "inputs_feat[\"x264\"] = [\"cabac\", \"ref\", \"deblock\", \"analyse\", \"me\", \"subme\", \"mixed_ref\", \"me_range\", \"trellis\", \n",
    "                \"8x8dct\", \"fast_pskip\", \"chroma_qp_offset\", \"bframes\", \"b_pyramid\", \"b_adapt\", \"direct\", \n",
    "                \"weightb\", \"open_gop\", \"weightp\", \"scenecut\", \"rc_lookahead\", \"mbtree\", \"qpmax\", \"aq-mode\"]\n",
    "inputs_feat[\"xz\"] = [\"memory\",\"format\",\"level\",\"depth\"]\n",
    "\n",
    "\n",
    "inputs_categ = dict()\n",
    "\n",
    "inputs_categ[\"gcc\"] = [\"optim\"]\n",
    "inputs_categ[\"lingeling\"] = []\n",
    "inputs_categ[\"nodejs\"] = []\n",
    "inputs_categ[\"poppler\"] = [\"format\"]\n",
    "inputs_categ[\"sqlite\"] = []\n",
    "inputs_categ[\"x264\"] = ['analyse', 'me', 'direct', 'deblock']\n",
    "inputs_categ[\"xz\"] = ['memory', 'format']\n",
    "\n",
    "\n",
    "for ns in name_systems:\n",
    "    \n",
    "    data_path = data_dir+ns+'/'\n",
    "    \n",
    "    inputs = sorted(os.listdir(data_path))\n",
    "    inputs.remove('others')\n",
    "\n",
    "    inputs_name[ns] = inputs\n",
    "    inputs_count[ns] = len(inputs)\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        loc = data_path+inputs[i]\n",
    "        data[ns, i] = pd.read_csv(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3 code and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the performance ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratios(ns, perf):\n",
    "    \n",
    "    ratios = []\n",
    "    \n",
    "    nb_inputs = inputs_count[ns]\n",
    "    \n",
    "    for index_target in range(nb_inputs):\n",
    "\n",
    "        list_ratios = []\n",
    "        s1 = np.max(data[ns, index_target][perf])\n",
    "\n",
    "        for i in range(10):\n",
    "            index_source = np.random.randint(nb_inputs)\n",
    "            s2 = data[ns, index_target][perf][np.argmax(data[ns, index_source][perf])]\n",
    "            # we drop the ratios that are division per 0 or nan values\n",
    "            if not np.isnan(s1) and not np.isnan(s2) and s2!=0:\n",
    "                # we drop the ratios too high because it is just due to the fact that s2 is too low \n",
    "                # and it increases the standard deviation\n",
    "                if int(s1/s2) <= 50:\n",
    "                    list_ratios.append(s1/s2)\n",
    "\n",
    "        ratios.append(np.nanmean(list_ratios))\n",
    "\n",
    "    return (np.nanmean(ratios), \n",
    "            np.nanstd(ratios), \n",
    "            np.nanpercentile(ratios,5),\n",
    "            np.nanpercentile(ratios,25),\n",
    "            np.nanmedian(ratios),\n",
    "            np.nanpercentile(ratios,75),\n",
    "            np.nanpercentile(ratios,95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the table of ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\caption{Performance ratio distributions across inputs, \n",
      "      for different software systems and different performance properties. \n",
      "      In lines, \\textit{Avg} the avegrae performance ratio. \n",
      "      \\textit{Std} the standard deviation. \n",
      "      \\textit{$5^{th}$} the $5^{th}$ percentile.\n",
      "      \\textit{Q1} the first quartile.\n",
      "      \\textit{Q2} the median.\n",
      "      \\textit{Q3} the third quartile.\n",
      "      \\textit{$95^{th}$} the $95^{th}$ percentile.\n",
      "      Due to space constraints, we arbitrarly select few performance properties.}\n",
      "\\label{tab:ratios}\n",
      "\\vspace*{-0.4cm}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "\\textbf{\\textit{System}}\n",
      " & \\multicolumn{3}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{gcc}}}}\n",
      " & \\multicolumn{3}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{lingeling}}}}\n",
      " & \\multicolumn{1}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{nodejs}}}}\n",
      " & \\multicolumn{2}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{poppler}}}}\n",
      " & \\multicolumn{3}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{sqlite}}}}\n",
      " & \\multicolumn{5}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{x264}}}}\n",
      " & \\multicolumn{2}{|c|}{\\cellcolor[HTML]{e8e8e8}{\\textbf{\\textit{xz}}}}\n",
      " \\tabularnewline \\hline\n",
      "Perf. P\n",
      " & \\footnotesize ctime\n",
      " & \\footnotesize exec\n",
      " & \\footnotesize size\n",
      " & \\footnotesize confl\n",
      " & \\footnotesize cps\n",
      " & \\footnotesize reduc\n",
      " & \\footnotesize ops\n",
      " & \\footnotesize size\n",
      " & \\footnotesize time\n",
      " & \\footnotesize q1\n",
      " & \\footnotesize q12\n",
      " & \\footnotesize q14\n",
      " & \\footnotesize cpu\n",
      " & \\footnotesize etime\n",
      " & \\footnotesize fps\n",
      " & \\footnotesize kbs\n",
      " & \\footnotesize size\n",
      " & \\footnotesize size\n",
      " & \\footnotesize time\n",
      " \\tabularnewline \\hline\n",
      "Avg\n",
      " & 1.07\n",
      " & 1.12\n",
      " & 1.44\n",
      " & 2.09\n",
      " & 1.7\n",
      " & 1.38\n",
      " & 1.72\n",
      " & 1.59\n",
      " & 2.72\n",
      " & 1.03\n",
      " & 1.08\n",
      " & 1.07\n",
      " & 1.44\n",
      " & 1.42\n",
      " & 1.1\n",
      " & 1.11\n",
      " & 1.11\n",
      " & 1.0\n",
      " & 1.08\n",
      " \\tabularnewline \\hline\n",
      "Std\n",
      " & 0.07\n",
      " & 0.04\n",
      " & 0.67\n",
      " & 2.29\n",
      " & 1.58\n",
      " & 0.78\n",
      " & 1.91\n",
      " & 1.42\n",
      " & 3.79\n",
      " & 0.02\n",
      " & 0.05\n",
      " & 0.05\n",
      " & 1.51\n",
      " & 1.2\n",
      " & 0.12\n",
      " & 0.13\n",
      " & 0.13\n",
      " & 0.0\n",
      " & 0.08\n",
      " \\tabularnewline \\hline\n",
      "$5^{th}$\n",
      " & 1.0\n",
      " & 1.05\n",
      " & 1.01\n",
      " & 1.02\n",
      " & 1.02\n",
      " & 1.0\n",
      " & 1.01\n",
      " & 1.0\n",
      " & 1.02\n",
      " & 1.01\n",
      " & 1.02\n",
      " & 1.01\n",
      " & 1.05\n",
      " & 1.05\n",
      " & 1.02\n",
      " & 1.01\n",
      " & 1.02\n",
      " & 1.0\n",
      " & 1.0\n",
      " \\tabularnewline \\hline\n",
      "Q1\n",
      " & 1.02\n",
      " & 1.09\n",
      " & 1.12\n",
      " & 1.05\n",
      " & 1.06\n",
      " & 1.04\n",
      " & 1.09\n",
      " & 1.0\n",
      " & 1.14\n",
      " & 1.02\n",
      " & 1.03\n",
      " & 1.03\n",
      " & 1.12\n",
      " & 1.12\n",
      " & 1.04\n",
      " & 1.03\n",
      " & 1.05\n",
      " & 1.0\n",
      " & 1.02\n",
      " \\tabularnewline \\hline\n",
      "Q2\n",
      " & 1.05\n",
      " & 1.12\n",
      " & 1.21\n",
      " & 1.15\n",
      " & 1.14\n",
      " & 1.11\n",
      " & 1.16\n",
      " & 1.08\n",
      " & 1.38\n",
      " & 1.03\n",
      " & 1.07\n",
      " & 1.06\n",
      " & 1.21\n",
      " & 1.21\n",
      " & 1.07\n",
      " & 1.07\n",
      " & 1.07\n",
      " & 1.0\n",
      " & 1.05\n",
      " \\tabularnewline \\hline\n",
      "Q3\n",
      " & 1.11\n",
      " & 1.13\n",
      " & 1.42\n",
      " & 1.5\n",
      " & 1.43\n",
      " & 1.28\n",
      " & 1.55\n",
      " & 1.53\n",
      " & 2.27\n",
      " & 1.04\n",
      " & 1.11\n",
      " & 1.09\n",
      " & 1.4\n",
      " & 1.39\n",
      " & 1.11\n",
      " & 1.15\n",
      " & 1.12\n",
      " & 1.0\n",
      " & 1.1\n",
      " \\tabularnewline \\hline\n",
      "$95^{th}$\n",
      " & 1.19\n",
      " & 1.18\n",
      " & 2.66\n",
      " & 7.19\n",
      " & 4.72\n",
      " & 2.89\n",
      " & 4.07\n",
      " & 3.72\n",
      " & 9.92\n",
      " & 1.08\n",
      " & 1.17\n",
      " & 1.14\n",
      " & 2.17\n",
      " & 2.05\n",
      " & 1.27\n",
      " & 1.34\n",
      " & 1.29\n",
      " & 1.0\n",
      " & 1.25\n",
      " \\tabularnewline \\hline\n",
      "\\end{tabular}\n",
      "\\vspace*{-0.3cm}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "fontsize = \"\\\\footnotesize \"\n",
    "fontsize_number = \"\"\n",
    "\n",
    "perfs = []\n",
    "for ns in sorted(name_systems):\n",
    "    for perf in sorted(inputs_perf[ns]):\n",
    "        perfs.append(perf[0:5])\n",
    "\n",
    "print(\"\\\\begin{table*}\")\n",
    "print(\"\"\"\\\\caption{Performance ratio distributions across inputs, \n",
    "      for different software systems and different performance properties. \n",
    "      In lines, \\\\textit{Avg} the avegrae performance ratio. \n",
    "      \\\\textit{Std} the standard deviation. \n",
    "      \\\\textit{$5^{th}$} the $5^{th}$ percentile.\n",
    "      \\\\textit{Q1} the first quartile.\n",
    "      \\\\textit{Q2} the median.\n",
    "      \\\\textit{Q3} the third quartile.\n",
    "      \\\\textit{$95^{th}$} the $95^{th}$ percentile.\n",
    "      Due to space constraints, we arbitrarly select few performance properties.}\"\"\")\n",
    "print(\"\\\\label{tab:ratios}\")\n",
    "print(\"\\\\vspace*{-0.4cm}\")\n",
    "print(\"\\\\begin{tabular}{|\"+\"c|\"*(len(perfs)+1)+\"}\")\n",
    "print(\"\\hline\")\n",
    "print(fontsize_number+\"\\\\textbf{\\\\textit{System}}\")\n",
    "for ns in sorted(name_systems):\n",
    "    print(\" & \\\\multicolumn{\"+str(len(inputs_perf[ns]))+\"}{|c|}{\"+fontsize_number+\n",
    "          \"\\\\cellcolor[HTML]{e8e8e8}{\\\\textbf{\\\\textit{\"+ns+\"}}}}\")\n",
    "print(\" \\\\tabularnewline \\\\hline\")\n",
    "\n",
    "print(fontsize_number+\"Perf. P\")\n",
    "for p in perfs:\n",
    "    print(\" & \"+fontsize+p)\n",
    "print(\" \\\\tabularnewline \\\\hline\")\n",
    "\n",
    "ratio = dict()\n",
    "for ns in sorted(name_systems):\n",
    "    for perf in sorted(inputs_perf[ns]):\n",
    "        numbers = [np.round(k,2) for k in get_ratios(ns, perf)]\n",
    "        for i in range(len(numbers)):\n",
    "            ratio[ns, perf, i] = numbers[i] \n",
    "\n",
    "header = [\"Avg\", \"Std\", \"$5^{th}$\", \"Q1\", \"Q2\", \"Q3\", \"$95^{th}$\"]\n",
    "\n",
    "for i in range(len(header)):\n",
    "    #if i >=1:\n",
    "    print(fontsize_number+header[i])\n",
    "    for ns in sorted(name_systems):\n",
    "        for perf in inputs_perf[ns]:\n",
    "            print(\" & \"+fontsize_number+str(ratio[ns, perf, i]))\n",
    "    #else:\n",
    "    #    for ns in sorted(name_systems):\n",
    "    #        for perf in inputs_perf[ns]:\n",
    "    #            print(\" & \"+str(ratio[ns, perf, 0])+\" $\\pm$ \"+str(ratio[ns, perf, 1]))\n",
    "    print(\" \\\\tabularnewline \\\\hline\")\n",
    "\n",
    "print(\"\\\\end{tabular}\")\n",
    "print(\"\\\\vspace*{-0.3cm}\")\n",
    "print(\"\\\\end{table*}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
